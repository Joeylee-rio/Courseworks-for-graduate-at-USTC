0.002513776878247484
(tensor([6.5132], device='cuda:0'), tensor([0.2295], device='cuda:0'))
3500
Net(
  (inp_layer): Linear(in_features=1, out_features=10, bias=True)
  (hiddens): ModuleList(
    (0): Linear(in_features=10, out_features=10, bias=True)
    (1): Linear(in_features=10, out_features=10, bias=True)
    (2): Linear(in_features=10, out_features=10, bias=True)
  )
  (out_layer): Linear(in_features=10, out_features=1, bias=True)
)
step: 10 , loss: 0.290584921836853
0.24633382260799408
step: 20 , loss: 0.2842616140842438
0.1747862547636032
step: 30 , loss: 0.02351325750350952
0.02156648226082325
step: 40 , loss: 0.01065130066126585
0.022162744775414467
step: 50 , loss: 0.010294167324900627
0.022519007325172424
step: 60 , loss: 0.011761324480175972
0.02084297686815262
step: 70 , loss: 0.025702618062496185
0.02050737291574478
step: 80 , loss: 0.030315201729536057
0.018869608640670776
step: 90 , loss: 0.02420678734779358
0.018808700144290924
step: 100 , loss: 0.008796869777143002
0.02076862007379532
step: 110 , loss: 0.022076716646552086
0.019386325031518936
step: 120 , loss: 0.008555266074836254
0.01821005530655384
step: 130 , loss: 0.02292330004274845
0.018540507182478905
step: 140 , loss: 0.011344139464199543
0.01799384504556656
step: 150 , loss: 0.018750712275505066
0.018441112712025642
step: 160 , loss: 0.01165886502712965
0.01876530796289444
step: 170 , loss: 0.011758754961192608
0.018440064042806625
step: 180 , loss: 0.015797540545463562
0.01819698140025139
step: 190 , loss: 0.006059123668819666
0.01820116676390171
step: 200 , loss: 0.001547390129417181
0.018358144909143448
step: 210 , loss: 0.018585391342639923
0.01776382513344288
step: 220 , loss: 0.013306386768817902
0.01825292408466339
step: 230 , loss: 0.005861704703420401
0.017845705151557922
step: 240 , loss: 0.02387169562280178
0.01880330592393875
step: 250 , loss: 0.016446933150291443
0.018455570563673973
step: 260 , loss: 0.012117807753384113
0.01791529357433319
step: 270 , loss: 0.019792988896369934
0.017990699037909508
step: 280 , loss: 0.018550893291831017
0.018666813150048256
step: 290 , loss: 0.010718002915382385
0.017934191972017288
step: 300 , loss: 0.011699052527546883
0.017852632328867912
step: 310 , loss: 0.028045639395713806
0.01803726889193058
step: 320 , loss: 0.01688162051141262
0.018578380346298218
step: 330 , loss: 0.019339943304657936
0.018333949148654938
step: 340 , loss: 0.03713560476899147
0.01763920485973358
step: 350 , loss: 0.03268393874168396
0.01830977573990822
step: 360 , loss: 0.012229341082274914
0.01763615943491459
step: 370 , loss: 0.018474727869033813
0.017704378813505173
step: 380 , loss: 0.02025802992284298
0.018297137692570686
step: 390 , loss: 0.025568386539816856
0.017899151891469955
step: 400 , loss: 0.02702699601650238
0.018235541880130768
step: 410 , loss: 0.018239706754684448
0.0175938718020916
step: 420 , loss: 0.01444584596902132
0.01840166375041008
step: 430 , loss: 0.010235837660729885
0.018018536269664764
step: 440 , loss: 0.009716828353703022
0.017899159342050552
step: 450 , loss: 0.013527794741094112
0.017677897587418556
step: 460 , loss: 0.031198756769299507
0.01762205734848976
step: 470 , loss: 0.0065222568809986115
0.017637168988585472
step: 480 , loss: 0.0081576993688941
0.017843186855316162
step: 490 , loss: 0.007830778136849403
0.01763029769062996
step: 500 , loss: 0.007392422761768103
0.017962133511900902
lr: 0.01
activation function type: sigmoid
depth: 4
width: 10
test_loss: 0.017335187643766403
