0.002513776878247484
(tensor([6.5132], device='cuda:0'), tensor([0.2295], device='cuda:0'))
3500
Net(
  (inp_layer): Linear(in_features=1, out_features=13, bias=True)
  (hiddens): ModuleList(
    (0): Linear(in_features=13, out_features=13, bias=True)
    (1): Linear(in_features=13, out_features=13, bias=True)
  )
  (out_layer): Linear(in_features=13, out_features=1, bias=True)
)
step: 10 , loss: 0.017802953720092773
0.030482513830065727
step: 20 , loss: 0.01898394152522087
0.020395522937178612
step: 30 , loss: 0.018845651298761368
0.01538883987814188
step: 40 , loss: 0.020145324990153313
0.009657981805503368
step: 50 , loss: 0.002498483285307884
0.0045534176751971245
step: 60 , loss: 0.0011510767508298159
0.0008144257590174675
step: 70 , loss: 0.0007258096593432128
0.00047551680472679436
step: 80 , loss: 0.000559459556825459
0.0003996962623205036
step: 90 , loss: 0.00030517118284478784
0.0003728310111910105
step: 100 , loss: 0.000558857514988631
0.002879864303395152
step: 110 , loss: 0.003863908816128969
0.0014179045101627707
step: 120 , loss: 0.0004594961937982589
0.000543919566553086
step: 130 , loss: 0.0005740615306422114
0.00039334382745437324
step: 140 , loss: 0.0004413693677634001
0.0008559359703212976
step: 150 , loss: 0.00020482842228375375
0.0021459106355905533
step: 160 , loss: 0.0016255585942417383
0.0021575179416686296
step: 170 , loss: 0.00021744593686889857
0.00016880380280781537
step: 180 , loss: 0.000271946017164737
0.0002036058867815882
step: 190 , loss: 0.013028770685195923
0.004168304149061441
step: 200 , loss: 0.00024888027110137045
0.00014376781473401934
step: 210 , loss: 0.00027597826556302607
0.000621477491222322
step: 220 , loss: 0.00014145640307106078
9.270990994991735e-05
step: 230 , loss: 0.0002841113309841603
0.0001300731673836708
step: 240 , loss: 0.0001987693685805425
0.0001368247758364305
step: 250 , loss: 0.00043375464156270027
0.005138111300766468
step: 260 , loss: 0.0001963755494216457
0.00023256333952303976
step: 270 , loss: 0.0005697780870832503
0.0003815914678853005
step: 280 , loss: 0.00027243176009505987
0.00048446949222125113
step: 290 , loss: 0.00023506929574068636
8.789104322204366e-05
step: 300 , loss: 0.00023524256539531052
0.00016560900257900357
step: 310 , loss: 0.00022960989736020565
0.0017120441189035773
step: 320 , loss: 0.0001348851656075567
0.00030158323352225125
step: 330 , loss: 0.0008180527947843075
0.0002466914302203804
step: 340 , loss: 0.00010837118315976113
0.0001507147098891437
step: 350 , loss: 0.0005088519537821412
0.00021660150378011167
step: 360 , loss: 7.155543426051736e-05
0.00010116369230672717
step: 370 , loss: 0.00012297785724513233
6.836304964963347e-05
step: 380 , loss: 0.00014313976862467825
0.0003529613895807415
step: 390 , loss: 0.0009476644336245954
0.0012156005250290036
step: 400 , loss: 0.00025293961516581476
0.00011332824942655861
step: 410 , loss: 0.00019369598885532469
0.0004302636079955846
step: 420 , loss: 0.00014656060375273228
0.0002526105963625014
step: 430 , loss: 0.0006440740544348955
0.00030477542895823717
step: 440 , loss: 0.0004184927383903414
0.0018565189093351364
step: 450 , loss: 0.0006366387824527919
0.0009525365894660354
step: 460 , loss: 0.00011008620640495792
0.00010588202712824568
step: 470 , loss: 0.0002747679245658219
0.00021714721515309066
step: 480 , loss: 0.005529189482331276
0.0021863835863769054
step: 490 , loss: 0.0002583744062576443
0.00017208600183948874
step: 500 , loss: 0.00018156715668737888
0.00011973064829362556
lr: 0.01
activation function type: relu
depth: 3
width: 13
test_loss: 0.00010862655472010374
