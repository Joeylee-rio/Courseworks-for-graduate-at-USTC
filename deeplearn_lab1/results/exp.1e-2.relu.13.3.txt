Net(
  (inp_layer): Linear(in_features=1, out_features=13, bias=True)
  (hiddens): ModuleList(
    (0): Linear(in_features=13, out_features=13, bias=True)
    (1): Linear(in_features=13, out_features=13, bias=True)
  )
  (out_layer): Linear(in_features=13, out_features=1, bias=True)
)
step: 10 , loss: 0.014901198446750641
0.019601132720708847
step: 20 , loss: 0.0006613783771172166
0.002487109275534749
step: 30 , loss: 0.0008721392368897796
0.002636765129864216
step: 40 , loss: 0.0004166118160355836
0.0005877612857148051
step: 50 , loss: 0.0017866521375253797
0.0011854732874780893
step: 60 , loss: 0.003796566277742386
0.005663998890668154
step: 70 , loss: 0.0002617540012579411
0.0006038743304088712
step: 80 , loss: 0.002476564608514309
0.0009809629991650581
step: 90 , loss: 0.0014636252308264375
0.0006055511767044663
step: 100 , loss: 0.0002145633625332266
0.0001994924823520705
step: 110 , loss: 0.0009706563432700932
0.00039637222653254867
step: 120 , loss: 0.0002015693171415478
0.00036398257361724973
step: 130 , loss: 0.0006442199228331447
0.0002500728005543351
step: 140 , loss: 0.0011941390112042427
0.0005069952458143234
step: 150 , loss: 0.00025918480241671205
0.0006579261389560997
step: 160 , loss: 0.0006323857232928276
0.00045806262642145157
step: 170 , loss: 0.0003979328030254692
0.0001559675147291273
step: 180 , loss: 0.00013640950783155859
0.0002585908805485815
step: 190 , loss: 0.005128821823745966
0.004010363016277552
step: 200 , loss: 0.00015307244029827416
0.00030877013341523707
step: 210 , loss: 0.00026861403603106737
0.0002738916373346001
step: 220 , loss: 0.00390259874984622
0.0003872208180837333
step: 230 , loss: 0.002960014855489135
0.0050528631545603275
step: 240 , loss: 0.00016679249529261142
0.00041402308852411807
step: 250 , loss: 0.0004785602795891464
0.0003378914261702448
step: 260 , loss: 0.00043895700946450233
0.0007119048968888819
step: 270 , loss: 0.003838977310806513
0.003051450476050377
step: 280 , loss: 0.00033049509511329234
0.0007169449236243963
step: 290 , loss: 0.0003647570847533643
0.00027192660490982234
step: 300 , loss: 0.0006209136336110532
0.0008841362432576716
step: 310 , loss: 0.00029147876193746924
0.0006531020626425743
step: 320 , loss: 0.00038804177893325686
0.00043948867823928595
step: 330 , loss: 0.00028758664848282933
0.00037041789619252086
step: 340 , loss: 0.00034760497510433197
0.0009626447572372854
step: 350 , loss: 0.0002615173580124974
0.0003268890141043812
step: 360 , loss: 0.0005797144258394837
0.0007714849198237062
step: 370 , loss: 0.0016512785805389285
0.0005831945454701781
step: 380 , loss: 0.0010199456010013819
0.005394638050347567
step: 390 , loss: 0.00014564688899554312
0.0003025186888407916
step: 400 , loss: 0.00024817074881866574
0.000394531263737008
step: 410 , loss: 0.00021928540081717074
0.00033421689295209944
step: 420 , loss: 0.00021455738169606775
0.0004547156277112663
step: 430 , loss: 0.0004143199184909463
0.0011252358090132475
step: 440 , loss: 0.0006698978249914944
0.0012504010228440166
step: 450 , loss: 0.0002749856503214687
0.0003334975626785308
step: 460 , loss: 0.0004633057105820626
0.0002859634405467659
step: 470 , loss: 0.0003670042206067592
0.0003662623930722475
step: 480 , loss: 0.0002899507526308298
0.00033820123644545674
step: 490 , loss: 0.00043769937474280596
0.00033733330201357603
step: 500 , loss: 0.0008735269075259566
0.0006112903356552124
lr: 0.01
activation function type: relu
depth: 3
width: 13
test_loss: 0.0006094011478126049
