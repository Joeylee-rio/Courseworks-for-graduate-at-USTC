0.002513776878247484
(tensor([6.5132], device='cuda:0'), tensor([0.2295], device='cuda:0'))
3500
Net(
  (inp_layer): Linear(in_features=1, out_features=13, bias=True)
  (hiddens): ModuleList(
    (0): Linear(in_features=13, out_features=13, bias=True)
    (1): Linear(in_features=13, out_features=13, bias=True)
  )
  (out_layer): Linear(in_features=13, out_features=1, bias=True)
)
step: 10 , loss: 0.39854177832603455
0.34989407658576965
step: 20 , loss: 0.40833258628845215
0.33850008249282837
step: 30 , loss: 0.3441998064517975
0.3304232358932495
step: 40 , loss: 0.28334274888038635
0.24619287252426147
step: 50 , loss: 0.1587226837873459
0.16533254086971283
step: 60 , loss: 0.14151988923549652
0.14258567988872528
step: 70 , loss: 0.15798303484916687
0.13912494480609894
step: 80 , loss: 0.10425607115030289
0.13072240352630615
step: 90 , loss: 0.09196152538061142
0.12500183284282684
step: 100 , loss: 0.09568707644939423
0.12697194516658783
step: 110 , loss: 0.11927508562803268
0.11622828245162964
step: 120 , loss: 0.15401232242584229
0.11366689205169678
step: 130 , loss: 0.14743247628211975
0.10857250541448593
step: 140 , loss: 0.09899542480707169
0.10808005928993225
step: 150 , loss: 0.1082068383693695
0.10380922257900238
step: 160 , loss: 0.07634538412094116
0.10103312134742737
step: 170 , loss: 0.08005654066801071
0.10004077106714249
step: 180 , loss: 0.08093661814928055
0.09717133641242981
step: 190 , loss: 0.0515873022377491
0.08860298246145248
step: 200 , loss: 0.07817578315734863
0.0841367244720459
step: 210 , loss: 0.08249437808990479
0.08006756007671356
step: 220 , loss: 0.07977861911058426
0.0730443000793457
step: 230 , loss: 0.06353731453418732
0.06595491617918015
step: 240 , loss: 0.06259957700967789
0.05552605167031288
step: 250 , loss: 0.04721079766750336
0.03915000334382057
step: 260 , loss: 0.03230372816324234
0.02420184761285782
step: 270 , loss: 0.010216456837952137
0.013819582760334015
step: 280 , loss: 0.012854521162807941
0.007456219755113125
step: 290 , loss: 0.001973142148926854
0.004147690255194902
step: 300 , loss: 0.0015298044309020042
0.003225406864657998
step: 310 , loss: 0.0022721916902810335
0.005246391054242849
step: 320 , loss: 0.002851234981790185
0.002183364937081933
step: 330 , loss: 0.0020920289680361748
0.001611557905562222
step: 340 , loss: 0.00341810192912817
0.0014568240148946643
step: 350 , loss: 0.0005056772497482598
0.0012707689311355352
step: 360 , loss: 0.0007382232579402626
0.0007959987269714475
step: 370 , loss: 0.0007441846537403762
0.000724391604308039
step: 380 , loss: 0.0003875804541166872
0.0007184500573202968
step: 390 , loss: 0.000536146922968328
0.00037800733116455376
step: 400 , loss: 0.000687947089318186
0.00027830334147438407
step: 410 , loss: 0.00013872893759980798
0.00024409734760411084
step: 420 , loss: 0.0002211185055784881
0.00036297415499575436
step: 430 , loss: 0.0002660380268935114
0.0005744654918089509
step: 440 , loss: 0.00062444934155792
0.0010098363272845745
step: 450 , loss: 0.00012909015640616417
0.00024898903211578727
step: 460 , loss: 0.000196127308299765
0.00016644112474750727
step: 470 , loss: 0.00025868203374557197
7.403843483189121e-05
step: 480 , loss: 0.0002935701049864292
0.00023628077178727835
step: 490 , loss: 4.886570241069421e-05
9.660823707235977e-05
step: 500 , loss: 0.0002248859964311123
0.00015469292702618986
lr: 0.0005
activation function type: tanh
depth: 3
width: 13
test_loss: 0.0001515820185886696
