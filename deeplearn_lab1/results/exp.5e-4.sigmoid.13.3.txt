0.002513776878247484
(tensor([6.5132], device='cuda:0'), tensor([0.2295], device='cuda:0'))
3500
Net(
  (inp_layer): Linear(in_features=1, out_features=13, bias=True)
  (hiddens): ModuleList(
    (0): Linear(in_features=13, out_features=13, bias=True)
    (1): Linear(in_features=13, out_features=13, bias=True)
  )
  (out_layer): Linear(in_features=13, out_features=1, bias=True)
)
step: 10 , loss: 0.5969417691230774
0.5195930004119873
step: 20 , loss: 0.42680057883262634
0.358656644821167
step: 30 , loss: 0.37595534324645996
0.3498234152793884
step: 40 , loss: 0.3929600417613983
0.3446738123893738
step: 50 , loss: 0.35030126571655273
0.3401186168193817
step: 60 , loss: 0.4372468590736389
0.33803266286849976
step: 70 , loss: 0.4301486611366272
0.33521944284439087
step: 80 , loss: 0.3778975307941437
0.3342743515968323
step: 90 , loss: 0.31337839365005493
0.33210352063179016
step: 100 , loss: 0.2739197611808777
0.33153417706489563
step: 110 , loss: 0.3938888609409332
0.3304734230041504
step: 120 , loss: 0.3877691924571991
0.3299309313297272
step: 130 , loss: 0.29656273126602173
0.32898885011672974
step: 140 , loss: 0.48579907417297363
0.32943785190582275
step: 150 , loss: 0.3066375255584717
0.3285585045814514
step: 160 , loss: 0.362048476934433
0.3281930685043335
step: 170 , loss: 0.31442028284072876
0.3277606964111328
step: 180 , loss: 0.26626840233802795
0.3275294005870819
step: 190 , loss: 0.32090115547180176
0.3202787935733795
step: 200 , loss: 0.19750478863716125
0.28323495388031006
step: 210 , loss: 0.29279544949531555
0.2641976773738861
step: 220 , loss: 0.18972761929035187
0.25736552476882935
step: 230 , loss: 0.2838113605976105
0.25379255414009094
step: 240 , loss: 0.21383650600910187
0.25135311484336853
step: 250 , loss: 0.37792640924453735
0.24946628510951996
step: 260 , loss: 0.2593547999858856
0.24514496326446533
step: 270 , loss: 0.3014237582683563
0.21722057461738586
step: 280 , loss: 0.055539511144161224
0.03884116932749748
step: 290 , loss: 0.013201662339270115
0.03311164677143097
step: 300 , loss: 0.014523382298648357
0.03052910789847374
step: 310 , loss: 0.02772844396531582
0.029352685436606407
step: 320 , loss: 0.019977927207946777
0.028292404487729073
step: 330 , loss: 0.030912747606635094
0.02783985808491707
step: 340 , loss: 0.05363387614488602
0.02688394859433174
step: 350 , loss: 0.01810566708445549
0.026414286345243454
step: 360 , loss: 0.02368680015206337
0.025612832978367805
step: 370 , loss: 0.034112103283405304
0.025085268542170525
step: 380 , loss: 0.009846930392086506
0.024540066719055176
step: 390 , loss: 0.03027729131281376
0.023946359753608704
step: 400 , loss: 0.03553919866681099
0.02342863194644451
step: 410 , loss: 0.016793271526694298
0.022903239354491234
step: 420 , loss: 0.01314546912908554
0.022361572831869125
step: 430 , loss: 0.016887996345758438
0.022021055221557617
step: 440 , loss: 0.014642676338553429
0.02144535258412361
step: 450 , loss: 0.02267504669725895
0.021099837496876717
step: 460 , loss: 0.016036570072174072
0.0207364559173584
step: 470 , loss: 0.03211113065481186
0.020393332466483116
step: 480 , loss: 0.021963877603411674
0.020100219175219536
step: 490 , loss: 0.013181369751691818
0.019660446792840958
step: 500 , loss: 0.020783156156539917
0.018537117168307304
lr: 0.0005
activation function type: sigmoid
depth: 3
width: 13
test_loss: 0.017719734460115433
