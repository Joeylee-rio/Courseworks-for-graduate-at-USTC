step: 10 , loss: 0.5347716808319092
0.49875786900520325
step: 20 , loss: 0.3231177031993866
0.44047099351882935
step: 30 , loss: 0.49714726209640503
0.3891497850418091
step: 40 , loss: 0.47580042481422424
0.36201295256614685
step: 50 , loss: 0.34116196632385254
0.3425978422164917
step: 60 , loss: 0.3468388319015503
0.3282665014266968
step: 70 , loss: 0.3059963583946228
0.3091508150100708
step: 80 , loss: 0.2362585961818695
0.29722803831100464
step: 90 , loss: 0.32381027936935425
0.28482526540756226
step: 100 , loss: 0.2823067903518677
0.27188512682914734
step: 110 , loss: 0.20046666264533997
0.25830769538879395
step: 120 , loss: 0.2535703778266907
0.2440563142299652
step: 130 , loss: 0.23976197838783264
0.2295261025428772
step: 140 , loss: 0.26644352078437805
0.21559487283229828
step: 150 , loss: 0.29873836040496826
0.20060400664806366
step: 160 , loss: 0.2839008867740631
0.18758487701416016
step: 170 , loss: 0.16133815050125122
0.17079666256904602
step: 180 , loss: 0.13221749663352966
0.15453287959098816
step: 190 , loss: 0.10805003345012665
0.13861587643623352
step: 200 , loss: 0.09417402744293213
0.1233733519911766
step: 210 , loss: 0.07986053079366684
0.10920444130897522
step: 220 , loss: 0.0922132134437561
0.09506788849830627
step: 230 , loss: 0.10104356706142426
0.08272144198417664
step: 240 , loss: 0.08687511831521988
0.07156950235366821
step: 250 , loss: 0.07064050436019897
0.06203065440058708
step: 260 , loss: 0.05822925269603729
0.05318393185734749
step: 270 , loss: 0.04245010018348694
0.045953843742609024
step: 280 , loss: 0.04280156269669533
0.03992201015353203
step: 290 , loss: 0.03450741618871689
0.03485133871436119
step: 300 , loss: 0.03553277626633644
0.030928105115890503
step: 310 , loss: 0.02389465644955635
0.02779686078429222
step: 320 , loss: 0.02694782242178917
0.02500206045806408
step: 330 , loss: 0.017771923914551735
0.02282036282122135
step: 340 , loss: 0.020141806453466415
0.021113546565175056
step: 350 , loss: 0.015472852624952793
0.01943194679915905
step: 360 , loss: 0.013863454572856426
0.018096260726451874
step: 370 , loss: 0.013546131551265717
0.017066188156604767
step: 380 , loss: 0.024037610739469528
0.01608656719326973
step: 390 , loss: 0.01346384733915329
0.01525787077844143
step: 400 , loss: 0.011638814583420753
0.014559688977897167
step: 410 , loss: 0.0074638440273702145
0.014087754301726818
step: 420 , loss: 0.015808790922164917
0.013409820385277271
step: 430 , loss: 0.012809354811906815
0.01303124614059925
step: 440 , loss: 0.01146758534014225
0.01257229782640934
step: 450 , loss: 0.007558356039226055
0.012089794501662254
step: 460 , loss: 0.006505622528493404
0.011701581068336964
step: 470 , loss: 0.011166326701641083
0.011391038075089455
step: 480 , loss: 0.008383447304368019
0.011269906535744667
step: 490 , loss: 0.006538763642311096
0.010876825079321861
step: 500 , loss: 0.011424785479903221
0.010863184928894043
lr: 0.001
activation function type: relu
depth: 4
width: 10
test_loss: 0.011426780372858047
