Net(
  (inp_layer): Linear(in_features=1, out_features=10, bias=True)
  (hiddens): ModuleList(
    (0): Linear(in_features=10, out_features=10, bias=True)
    (1): Linear(in_features=10, out_features=10, bias=True)
    (2): Linear(in_features=10, out_features=10, bias=True)
  )
  (out_layer): Linear(in_features=10, out_features=1, bias=True)
)
step: 10 , loss: 0.29013726115226746
0.31460702419281006
step: 20 , loss: 0.01423715241253376
0.022069107741117477
step: 30 , loss: 0.00517192343249917
0.016905199736356735
step: 40 , loss: 0.011330494657158852
0.013361460529267788
step: 50 , loss: 0.015576022677123547
0.01155786495655775
step: 60 , loss: 0.010279849171638489
0.008849536068737507
step: 70 , loss: 0.010379297658801079
0.0073930649086833
step: 80 , loss: 0.0010606307769194245
0.0057121641002595425
step: 90 , loss: 0.003331791842356324
0.0023539066314697266
step: 100 , loss: 0.0013517156476154923
0.0015426957979798317
step: 110 , loss: 0.0005491769406944513
0.002813916653394699
step: 120 , loss: 0.0015532171819359064
0.0012579603353515267
step: 130 , loss: 0.0017819306813180447
0.0018551605753600597
step: 140 , loss: 0.0016310644568875432
0.0020922664552927017
step: 150 , loss: 0.001958063803613186
0.0010096700862050056
step: 160 , loss: 0.0014892329927533865
0.0010703644948080182
step: 170 , loss: 0.001414258498698473
0.0012402947759255767
step: 180 , loss: 0.0016576291527599096
0.0013699750415980816
step: 190 , loss: 0.0007934537134133279
0.0029906821437180042
step: 200 , loss: 0.0007418002933263779
0.0009117996087297797
step: 210 , loss: 0.0014924880815669894
0.0018772605108097196
step: 220 , loss: 0.0009816136443987489
0.0017770471749827266
step: 230 , loss: 0.0006115981959737837
0.0021050344221293926
step: 240 , loss: 0.001010738778859377
0.0008689846144989133
step: 250 , loss: 0.0003421627916395664
0.001026483136229217
step: 260 , loss: 0.000629003974609077
0.000777529610786587
step: 270 , loss: 0.00031625182600691915
0.0007686089375056326
step: 280 , loss: 0.00048399658408015966
0.0007526080007664859
step: 290 , loss: 0.0008330765413120389
0.000832840334624052
step: 300 , loss: 0.0014445075066760182
0.0008565713651478291
step: 310 , loss: 0.0005106870667077601
0.0006918556755408645
step: 320 , loss: 0.0005120749119669199
0.0013126676203683019
step: 330 , loss: 0.00042309751734137535
0.0006877064006403089
step: 340 , loss: 0.0006384600419551134
0.000707433617208153
step: 350 , loss: 0.0004936435143463314
0.0008638069848529994
step: 360 , loss: 0.0004743995959870517
0.0005933858337812126
step: 370 , loss: 0.000449207000201568
0.0008145844331011176
step: 380 , loss: 0.0006507152575068176
0.0005509702023118734
step: 390 , loss: 0.00047809258103370667
0.0005624883924610913
step: 400 , loss: 0.0009162798523902893
0.0014017400098964572
step: 410 , loss: 0.0006097433506511152
0.0006722178659401834
step: 420 , loss: 0.0006077795987948775
0.0005876683862879872
step: 430 , loss: 0.0005096773384138942
0.0006155273877084255
step: 440 , loss: 0.0011898872908204794
0.00045948222395963967
step: 450 , loss: 0.001026376849040389
0.00044647319009527564
step: 460 , loss: 0.0010718540288507938
0.0005138225387781858
step: 470 , loss: 0.00044026528485119343
0.0005681816837750375
step: 480 , loss: 0.0005591405206359923
0.0005363738746382296
step: 490 , loss: 0.00025965931126847863
0.00045164747280068696
step: 500 , loss: 0.00044502891250886023
0.0005497046513482928
lr: 0.001
activation function type: relu
depth: 4
width: 10
test_loss: 0.0005625250050798059
