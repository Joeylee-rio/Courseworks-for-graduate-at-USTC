Net(
  (inp_layer): Linear(in_features=1, out_features=13, bias=True)
  (hiddens): ModuleList(
    (0): Linear(in_features=13, out_features=13, bias=True)
    (1): Linear(in_features=13, out_features=13, bias=True)
  )
  (out_layer): Linear(in_features=13, out_features=1, bias=True)
)
step: 10 , loss: 0.15025809407234192
0.12963412702083588
step: 20 , loss: 0.018026433885097504
0.02510463446378708
step: 30 , loss: 0.012418460100889206
0.022904442623257637
step: 40 , loss: 0.019242044538259506
0.020364293828606606
step: 50 , loss: 0.01888822391629219
0.013105307705700397
step: 60 , loss: 0.00594310462474823
0.006006412673741579
step: 70 , loss: 0.0029751425608992577
0.0032176130916923285
step: 80 , loss: 0.0019294330850243568
0.0020681803580373526
step: 90 , loss: 0.00364697421900928
0.0017785148229449987
step: 100 , loss: 0.000594675075262785
0.001577582210302353
step: 110 , loss: 0.0019419076852500439
0.001956966472789645
step: 120 , loss: 0.0011711912229657173
0.001532117836177349
step: 130 , loss: 0.002176484791561961
0.0019082321086898446
step: 140 , loss: 0.0013024588115513325
0.0014427979476749897
step: 150 , loss: 0.0021414097864180803
0.0014430967858061194
step: 160 , loss: 0.0011555807432159781
0.0013318052515387535
step: 170 , loss: 0.0022713656071573496
0.001657275017350912
step: 180 , loss: 0.0010632011108100414
0.0014176826225593686
step: 190 , loss: 0.001327731879428029
0.0014813302550464869
step: 200 , loss: 0.0011118180118501186
0.0013121170923113823
step: 210 , loss: 0.0011371022555977106
0.0013573013711720705
step: 220 , loss: 0.0012003814335912466
0.0014665547059848905
step: 230 , loss: 0.0013214945793151855
0.001433847239241004
step: 240 , loss: 0.0026349364779889584
0.0017336028395220637
step: 250 , loss: 0.0008182429010048509
0.001487020985223353
step: 260 , loss: 0.000770790851674974
0.0012612685095518827
step: 270 , loss: 0.0011551425559446216
0.0014975586673244834
step: 280 , loss: 0.0018616719171404839
0.001287701423279941
step: 290 , loss: 0.0005212983814999461
0.0012532004620879889
step: 300 , loss: 0.0011373176239430904
0.0014652627287432551
step: 310 , loss: 0.001159002771601081
0.0012762865517288446
step: 320 , loss: 0.0016348166391253471
0.0016553126042708755
step: 330 , loss: 0.0016687994357198477
0.001334988628514111
step: 340 , loss: 0.0012199109187349677
0.0013784314505755901
step: 350 , loss: 0.0015157717280089855
0.0013190332101657987
step: 360 , loss: 0.0009672974701970816
0.001260270830243826
step: 370 , loss: 0.0010592598700895905
0.001531164045445621
step: 380 , loss: 0.0014561458956450224
0.001356994966045022
step: 390 , loss: 0.0009856043616309762
0.0017068596789613366
step: 400 , loss: 0.0008021286921575665
0.0011435470078140497
step: 410 , loss: 0.0017211451195180416
0.0012587624369189143
step: 420 , loss: 0.0016975949984043837
0.001166907255537808
step: 430 , loss: 0.0009652681765146554
0.0011140782153233886
step: 440 , loss: 0.0013102740049362183
0.001122210407629609
step: 450 , loss: 0.00031240982934832573
0.001121664885431528
step: 460 , loss: 0.0004379224847070873
0.0011484809219837189
step: 470 , loss: 0.0014282262418419123
0.001371272373944521
step: 480 , loss: 0.0016039173351600766
0.001098722219467163
step: 490 , loss: 0.0022173074539750814
0.0011923342244699597
step: 500 , loss: 0.0011398966889828444
0.0010223430581390858
lr: 0.001
activation function type: relu
depth: 3
width: 13
test_loss: 0.0010468987748026848
