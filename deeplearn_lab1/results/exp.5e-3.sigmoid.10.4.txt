Net(
  (inp_layer): Linear(in_features=1, out_features=10, bias=True)
  (hiddens): ModuleList(
    (0): Linear(in_features=10, out_features=10, bias=True)
    (1): Linear(in_features=10, out_features=10, bias=True)
    (2): Linear(in_features=10, out_features=10, bias=True)
  )
  (out_layer): Linear(in_features=10, out_features=1, bias=True)
)
step: 10 , loss: 0.33488765358924866
0.3449293375015259
step: 20 , loss: 0.26875245571136475
0.34092390537261963
step: 30 , loss: 0.19756031036376953
0.2562646269798279
step: 40 , loss: 0.1366157829761505
0.1571018546819687
step: 50 , loss: 0.02543044462800026
0.019866257905960083
step: 60 , loss: 0.023412911221385002
0.019750503823161125
step: 70 , loss: 0.024543344974517822
0.01904931850731373
step: 80 , loss: 0.009939935058355331
0.018902314826846123
step: 90 , loss: 0.02553885616362095
0.01870577409863472
step: 100 , loss: 0.010818383656442165
0.019021885469555855
step: 110 , loss: 0.005151992663741112
0.017865261062979698
step: 120 , loss: 0.019183004274964333
0.018119588494300842
step: 130 , loss: 0.021136971190571785
0.0180915929377079
step: 140 , loss: 0.022021688520908356
0.01783979870378971
step: 150 , loss: 0.01907782070338726
0.01764722354710102
step: 160 , loss: 0.02486928179860115
0.017881382256746292
step: 170 , loss: 0.035302020609378815
0.017352912575006485
step: 180 , loss: 0.014959708787500858
0.017714204266667366
step: 190 , loss: 0.013524284586310387
0.016329430043697357
step: 200 , loss: 0.002439008792862296
0.016172338277101517
step: 210 , loss: 0.02076203003525734
0.0162439476698637
step: 220 , loss: 0.0027565881609916687
0.016071461141109467
step: 230 , loss: 0.01013959664851427
0.01613037846982479
step: 240 , loss: 0.005423885770142078
0.01633305288851261
step: 250 , loss: 0.016779910773038864
0.01655399426817894
step: 260 , loss: 0.009870624169707298
0.01597132533788681
step: 270 , loss: 7.468114199582487e-05
0.016038721427321434
step: 280 , loss: 0.0070816343650221825
0.016131991520524025
step: 290 , loss: 0.029284220188856125
0.01601988822221756
step: 300 , loss: 0.03081277757883072
0.016164803877472878
step: 310 , loss: 0.009556381963193417
0.015925684943795204
step: 320 , loss: 0.012054050341248512
0.01609949953854084
step: 330 , loss: 0.005677422974258661
0.015971945598721504
step: 340 , loss: 0.02172970026731491
0.016076836735010147
step: 350 , loss: 0.002167623955756426
0.016390705481171608
step: 360 , loss: 0.0029595557134598494
0.016195762902498245
step: 370 , loss: 0.0038197149988263845
0.016219228506088257
step: 380 , loss: 0.03604178875684738
0.016236765310168266
step: 390 , loss: 0.01010148786008358
0.01613459177315235
step: 400 , loss: 0.01137915626168251
0.015943553298711777
step: 410 , loss: 0.017954248934984207
0.016196968033909798
step: 420 , loss: 0.030715622007846832
0.01636171154677868
step: 430 , loss: 0.014461057260632515
0.015981322154402733
step: 440 , loss: 0.01250938605517149
0.015887752175331116
step: 450 , loss: 0.008403950370848179
0.015998803079128265
step: 460 , loss: 0.006615540012717247
0.0158323235809803
step: 470 , loss: 0.02744283899664879
0.016067981719970703
step: 480 , loss: 0.014224146492779255
0.015948962420225143
step: 490 , loss: 0.012299388647079468
0.01603185571730137
step: 500 , loss: 0.004372619558125734
0.01585942693054676
lr: 0.005
activation function type: sigmoid
depth: 4
width: 10
test_loss: 0.017347894608974457
