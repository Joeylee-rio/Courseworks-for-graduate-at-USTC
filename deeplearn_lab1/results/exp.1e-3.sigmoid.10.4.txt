0.002513776878247484
(tensor([6.5132], device='cuda:0'), tensor([0.2295], device='cuda:0'))
3500
Net(
  (inp_layer): Linear(in_features=1, out_features=10, bias=True)
  (hiddens): ModuleList(
    (0): Linear(in_features=10, out_features=10, bias=True)
    (1): Linear(in_features=10, out_features=10, bias=True)
    (2): Linear(in_features=10, out_features=10, bias=True)
  )
  (out_layer): Linear(in_features=10, out_features=1, bias=True)
)
step: 10 , loss: 0.4406388998031616
0.40704345703125
step: 20 , loss: 0.510694682598114
0.33086487650871277
step: 30 , loss: 0.43943119049072266
0.32757771015167236
step: 40 , loss: 0.396724671125412
0.326397567987442
step: 50 , loss: 0.3220841884613037
0.3262617886066437
step: 60 , loss: 0.3227161169052124
0.3258250653743744
step: 70 , loss: 0.3353937864303589
0.3271733820438385
step: 80 , loss: 0.2604791522026062
0.3265649974346161
step: 90 , loss: 0.34203600883483887
0.32015255093574524
step: 100 , loss: 0.2813072204589844
0.2620048522949219
step: 110 , loss: 0.3037011921405792
0.24731814861297607
step: 120 , loss: 0.18444666266441345
0.24513959884643555
step: 130 , loss: 0.31426700949668884
0.244569331407547
step: 140 , loss: 0.2501288652420044
0.24458348751068115
step: 150 , loss: 0.21663111448287964
0.24477404356002808
step: 160 , loss: 0.20278184115886688
0.2442208230495453
step: 170 , loss: 0.35341039299964905
0.24366171658039093
step: 180 , loss: 0.02168501913547516
0.028170334175229073
step: 190 , loss: 0.009489225223660469
0.023876957595348358
step: 200 , loss: 0.004324089270085096
0.022686868906021118
step: 210 , loss: 0.023595144972205162
0.021970504894852638
step: 220 , loss: 0.014751946553587914
0.021354932337999344
step: 230 , loss: 0.008081888779997826
0.02102944441139698
step: 240 , loss: 0.026984628289937973
0.02066119574010372
step: 250 , loss: 0.019406605511903763
0.020308708772063255
step: 260 , loss: 0.013426532968878746
0.019959187135100365
step: 270 , loss: 0.021232539787888527
0.01946815848350525
step: 280 , loss: 0.019144538789987564
0.019309135153889656
step: 290 , loss: 0.011074029840528965
0.01855900138616562
step: 300 , loss: 0.008978182449936867
0.0179948341101408
step: 310 , loss: 0.027257530018687248
0.017845408990979195
step: 320 , loss: 0.01576148346066475
0.01747184246778488
step: 330 , loss: 0.017822174355387688
0.017332185059785843
step: 340 , loss: 0.03761769086122513
0.017363060265779495
step: 350 , loss: 0.032618168741464615
0.01740984618663788
step: 360 , loss: 0.010518922470510006
0.017150381579995155
step: 370 , loss: 0.016728835180401802
0.017225608229637146
step: 380 , loss: 0.018456345424056053
0.017327874898910522
step: 390 , loss: 0.02590992860496044
0.017081579193472862
step: 400 , loss: 0.025753699243068695
0.01696602813899517
step: 410 , loss: 0.017782609909772873
0.016943693161010742
step: 420 , loss: 0.014128332957625389
0.01723925769329071
step: 430 , loss: 0.009429042227566242
0.01721821539103985
step: 440 , loss: 0.008573569357395172
0.017063017934560776
step: 450 , loss: 0.011738612316548824
0.01692815124988556
step: 460 , loss: 0.031220242381095886
0.017160631716251373
step: 470 , loss: 0.005446947645395994
0.0169391892850399
step: 480 , loss: 0.00771805876865983
0.016995564103126526
step: 490 , loss: 0.006877760402858257
0.017107592895627022
step: 500 , loss: 0.006193839944899082
0.017140792682766914
lr: 0.001
activation function type: sigmoid
depth: 4
width: 10
test_loss: 0.016236180439591408
