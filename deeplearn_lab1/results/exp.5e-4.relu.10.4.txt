0.002513776878247484
(tensor([6.5132], device='cuda:0'), tensor([0.2295], device='cuda:0'))
3500
Net(
  (inp_layer): Linear(in_features=1, out_features=10, bias=True)
  (hiddens): ModuleList(
    (0): Linear(in_features=10, out_features=10, bias=True)
    (1): Linear(in_features=10, out_features=10, bias=True)
    (2): Linear(in_features=10, out_features=10, bias=True)
  )
  (out_layer): Linear(in_features=10, out_features=1, bias=True)
)
step: 10 , loss: 0.35389968752861023
0.34303152561187744
step: 20 , loss: 0.4836479723453522
0.3193020224571228
step: 30 , loss: 0.33492371439933777
0.2431308925151825
step: 40 , loss: 0.19288375973701477
0.17562860250473022
step: 50 , loss: 0.11316009610891342
0.10034845769405365
step: 60 , loss: 0.037145331501960754
0.05035017803311348
step: 70 , loss: 0.024809425696730614
0.027153892442584038
step: 80 , loss: 0.02489747852087021
0.017151003703475
step: 90 , loss: 0.01540404837578535
0.011248133145272732
step: 100 , loss: 0.0031729978509247303
0.00829237699508667
step: 110 , loss: 0.006091634277254343
0.004646328743547201
step: 120 , loss: 0.0009848920162767172
0.0031342175789177418
step: 130 , loss: 0.0023887939751148224
0.002201130148023367
step: 140 , loss: 0.0007297031697817147
0.0017084076534956694
step: 150 , loss: 0.0009162893402390182
0.0008346605463884771
step: 160 , loss: 0.0009683613898232579
0.0008269285899586976
step: 170 , loss: 0.0005801407969556749
0.0007341307937167585
step: 180 , loss: 0.0006206583348102868
0.0005584250902757049
step: 190 , loss: 0.0008793504675850272
0.0006165440427139401
step: 200 , loss: 0.00037431472446769476
0.0005334107554517686
step: 210 , loss: 0.0009849995840340853
0.0005382539238780737
step: 220 , loss: 0.0006085417699068785
0.0005363845848478377
step: 230 , loss: 0.00047528892173431814
0.00045931636122986674
step: 240 , loss: 0.00051116879330948
0.0004192342748865485
step: 250 , loss: 0.0007085466058924794
0.0007761128945276141
step: 260 , loss: 0.00046161800855770707
0.0004568329604808241
step: 270 , loss: 0.000340344849973917
0.0004528528661467135
step: 280 , loss: 0.0005092097562737763
0.0003943783522117883
step: 290 , loss: 0.00031724057043902576
0.0005227314541116357
step: 300 , loss: 0.000550321361515671
0.0005194883560761809
step: 310 , loss: 0.0005515237571671605
0.0004193194617982954
step: 320 , loss: 0.00028162653325125575
0.0005031475448049605
step: 330 , loss: 0.0003321947588119656
0.00038045732071623206
step: 340 , loss: 0.0006104505737312138
0.00040493972483091056
step: 350 , loss: 0.0004683719598688185
0.0004214347864035517
step: 360 , loss: 0.0005239105666987598
0.0005915577057749033
step: 370 , loss: 0.00048503000289201736
0.0003706153074745089
step: 380 , loss: 0.0003774162905756384
0.0004104890103917569
step: 390 , loss: 0.0004194454231765121
0.000401121360482648
step: 400 , loss: 0.0006166057428345084
0.00037844886537641287
step: 410 , loss: 0.00039975353865884244
0.00037261826219037175
step: 420 , loss: 0.0004341492895036936
0.00034038309240713716
step: 430 , loss: 0.0006510585080832243
0.0005109843332320452
step: 440 , loss: 0.0008397866040468216
0.0006452717934735119
step: 450 , loss: 0.0006589213153347373
0.00036684059887193143
step: 460 , loss: 0.00043971536797471344
0.00039571744855493307
step: 470 , loss: 0.0002575551625341177
0.0003983662754762918
step: 480 , loss: 0.00040218044887296855
0.00032545128487981856
step: 490 , loss: 0.00030105470796115696
0.00035408191615715623
step: 500 , loss: 0.0005471852491609752
0.0005895481444895267
lr: 0.0005
activation function type: relu
depth: 4
width: 10
test_loss: 0.0006992607959546149
