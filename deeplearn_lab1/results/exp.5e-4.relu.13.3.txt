step: 10 , loss: 0.49261415004730225
0.4909946918487549
step: 20 , loss: 0.45555663108825684
0.3866040110588074
step: 30 , loss: 0.3612874150276184
0.36092352867126465
step: 40 , loss: 0.35860157012939453
0.34540855884552
step: 50 , loss: 0.3011784553527832
0.329416424036026
step: 60 , loss: 0.20430095493793488
0.3166307508945465
step: 70 , loss: 0.35041457414627075
0.303932249546051
step: 80 , loss: 0.37378478050231934
0.29049748182296753
step: 90 , loss: 0.3440282940864563
0.2761194109916687
step: 100 , loss: 0.16095378994941711
0.2607993185520172
step: 110 , loss: 0.25741493701934814
0.24477793276309967
step: 120 , loss: 0.17379224300384521
0.22814661264419556
step: 130 , loss: 0.24529939889907837
0.21187525987625122
step: 140 , loss: 0.16617263853549957
0.1957540363073349
step: 150 , loss: 0.19032248854637146
0.18059836328029633
step: 160 , loss: 0.142933651804924
0.1661497801542282
step: 170 , loss: 0.1869320124387741
0.15234653651714325
step: 180 , loss: 0.12144199758768082
0.1395387500524521
step: 190 , loss: 0.12176751345396042
0.1279601752758026
step: 200 , loss: 0.08749811351299286
0.11801683902740479
step: 210 , loss: 0.10472220927476883
0.10901790112257004
step: 220 , loss: 0.12049872428178787
0.10179096460342407
step: 230 , loss: 0.07824290543794632
0.09560907632112503
step: 240 , loss: 0.09700070321559906
0.09067093580961227
step: 250 , loss: 0.061732515692710876
0.08678080886602402
step: 260 , loss: 0.06051422283053398
0.08375493437051773
step: 270 , loss: 0.12432649731636047
0.08160200715065002
step: 280 , loss: 0.06688820570707321
0.07944834977388382
step: 290 , loss: 0.11344291269779205
0.07790878415107727
step: 300 , loss: 0.10030625760555267
0.07701989263296127
step: 310 , loss: 0.05423771217465401
0.07641158252954483
step: 320 , loss: 0.051096975803375244
0.07531065493822098
step: 330 , loss: 0.09137830883264542
0.07465583831071854
step: 340 , loss: 0.11383518576622009
0.07420198619365692
step: 350 , loss: 0.03544004261493683
0.07380268722772598
step: 360 , loss: 0.05125068500638008
0.07352293282747269
step: 370 , loss: 0.07872943580150604
0.07319121062755585
step: 380 , loss: 0.06717503070831299
0.07294663041830063
step: 390 , loss: 0.05137431621551514
0.07274910807609558
step: 400 , loss: 0.028311114758253098
0.07256297767162323
step: 410 , loss: 0.062639981508255
0.0726967453956604
step: 420 , loss: 0.08463124930858612
0.07214511930942535
step: 430 , loss: 0.1344001442193985
0.07197865843772888
step: 440 , loss: 0.037212856113910675
0.07205260545015335
step: 450 , loss: 0.04101933538913727
0.0717969685792923
step: 460 , loss: 0.05337565392255783
0.07171396166086197
step: 470 , loss: 0.07999745011329651
0.0715339407324791
step: 480 , loss: 0.07637259364128113
0.07142285257577896
step: 490 , loss: 0.07155664265155792
0.07131819427013397
step: 500 , loss: 0.1526728868484497
0.07120692729949951
lr: 0.0005
activation function type: relu
depth: 3
width: 13
test_loss: 0.07465429604053497
