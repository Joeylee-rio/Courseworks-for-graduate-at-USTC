0.002513776878247484
(tensor([6.5132], device='cuda:0'), tensor([0.2295], device='cuda:0'))
3500
Net(
  (inp_layer): Linear(in_features=1, out_features=13, bias=True)
  (hiddens): ModuleList(
    (0): Linear(in_features=13, out_features=13, bias=True)
    (1): Linear(in_features=13, out_features=13, bias=True)
  )
  (out_layer): Linear(in_features=13, out_features=1, bias=True)
)
step: 10 , loss: 0.3859387934207916
0.3370625674724579
step: 20 , loss: 0.33693185448646545
0.28402385115623474
step: 30 , loss: 0.1993449181318283
0.2012876719236374
step: 40 , loss: 0.08596458286046982
0.07439915090799332
step: 50 , loss: 0.03306141868233681
0.040976546704769135
step: 60 , loss: 0.026230834424495697
0.037091732025146484
step: 70 , loss: 0.03607989847660065
0.03261955827474594
step: 80 , loss: 0.016595838591456413
0.02986147254705429
step: 90 , loss: 0.015599625185132027
0.026395034044981003
step: 100 , loss: 0.02176780439913273
0.023258676752448082
step: 110 , loss: 0.014043810777366161
0.020427750423550606
step: 120 , loss: 0.02722031995654106
0.01669241301715374
step: 130 , loss: 0.025845620781183243
0.013454459607601166
step: 140 , loss: 0.00788975227624178
0.011465692892670631
step: 150 , loss: 0.009798850864171982
0.0076364935375750065
step: 160 , loss: 0.0052237785421311855
0.005851909518241882
step: 170 , loss: 0.003577765543013811
0.003836956573650241
step: 180 , loss: 0.0020590699277818203
0.003007013350725174
step: 190 , loss: 0.0009750393219292164
0.002489858539775014
step: 200 , loss: 0.0021776119247078896
0.00226433458738029
step: 210 , loss: 0.0016371672973036766
0.0018817437812685966
step: 220 , loss: 0.0021482568699866533
0.0026508669834583998
step: 230 , loss: 0.0019485725788399577
0.0020144805312156677
step: 240 , loss: 0.0012196459574624896
0.002091329311951995
step: 250 , loss: 0.002495851367712021
0.0024497800040990114
step: 260 , loss: 0.0024366751313209534
0.0018509930232539773
step: 270 , loss: 0.0025185085833072662
0.0016773398965597153
step: 280 , loss: 0.0030941665172576904
0.0017593265511095524
step: 290 , loss: 0.0010737789561972022
0.00217300932854414
step: 300 , loss: 0.001637164270505309
0.002360329497605562
step: 310 , loss: 0.002919016405940056
0.001724193338304758
step: 320 , loss: 0.0024084083270281553
0.001793256145901978
step: 330 , loss: 0.0016756582772359252
0.0017674110131338239
step: 340 , loss: 0.0037414852995425463
0.0023159869015216827
step: 350 , loss: 0.001650107093155384
0.0016940736677497625
step: 360 , loss: 0.0024944867473095655
0.0017331917770206928
step: 370 , loss: 0.0018654974410310388
0.002215794287621975
step: 380 , loss: 0.0011356236645951867
0.0016605827258899808
step: 390 , loss: 0.003018184332177043
0.0021416700910776854
step: 400 , loss: 0.0031044287607073784
0.001696720952168107
step: 410 , loss: 0.002663098741322756
0.001990836812183261
step: 420 , loss: 0.001777441008016467
0.001672959653660655
step: 430 , loss: 0.0025818441063165665
0.0017174240201711655
step: 440 , loss: 0.0010911267017945647
0.0019388116197660565
step: 450 , loss: 0.002242360496893525
0.0021214126609265804
step: 460 , loss: 0.002400103723630309
0.0017501319525763392
step: 470 , loss: 0.0025395024567842484
0.0017855495680123568
step: 480 , loss: 0.0023023467510938644
0.001744232140481472
step: 490 , loss: 0.0015886761248111725
0.003107887925580144
step: 500 , loss: 0.002393518341705203
0.0017274117562919855
lr: 0.0005
activation function type: relu
depth: 3
width: 13
test_loss: 0.0020551097113639116
