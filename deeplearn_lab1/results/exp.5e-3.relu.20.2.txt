step: 10 , loss: 0.18341857194900513
0.1513722538948059
step: 20 , loss: 0.08007058501243591
0.06538023799657822
step: 30 , loss: 0.07066629081964493
0.05433802679181099
step: 40 , loss: 0.05921441689133644
0.04937746748328209
step: 50 , loss: 0.02866506017744541
0.04323996230959892
step: 60 , loss: 0.04548153653740883
0.034175217151641846
step: 70 , loss: 0.014798512682318687
0.02448810264468193
step: 80 , loss: 0.0068228766322135925
0.019479898735880852
step: 90 , loss: 0.013138743117451668
0.011824230663478374
step: 100 , loss: 0.010946143418550491
0.008337318897247314
step: 110 , loss: 0.005861353594809771
0.005371531471610069
step: 120 , loss: 0.003761949948966503
0.004022512584924698
step: 130 , loss: 0.007133476436138153
0.0026036216877400875
step: 140 , loss: 0.0045303902588784695
0.0021956772543489933
step: 150 , loss: 0.0017899370286613703
0.0019722082652151585
step: 160 , loss: 0.002253820886835456
0.0016199909150600433
step: 170 , loss: 0.0013034604489803314
0.0011959188850596547
step: 180 , loss: 0.001140387263149023
0.001051966566592455
step: 190 , loss: 0.002070983638986945
0.001422221539542079
step: 200 , loss: 0.0011379386996850371
0.0008823739481158555
step: 210 , loss: 0.003747263690456748
0.001484199077822268
step: 220 , loss: 0.0005720376502722502
0.0008794055320322514
step: 230 , loss: 0.0006392030627466738
0.001358731766231358
step: 240 , loss: 0.0010595725616440177
0.0007177565712481737
step: 250 , loss: 0.002572771394625306
0.0009701229864731431
step: 260 , loss: 0.0006120639154687524
0.001253423630259931
step: 270 , loss: 0.000921383616514504
0.0010854712454602122
step: 280 , loss: 0.0005215082783252001
0.0009566062944941223
step: 290 , loss: 0.0007430156110785902
0.0006857044063508511
step: 300 , loss: 0.0009717050706967711
0.0007500386564061046
step: 310 , loss: 0.000786405464168638
0.0006444051396101713
step: 320 , loss: 0.0017332225106656551
0.000856982369441539
step: 330 , loss: 0.0019077577162533998
0.000773404142819345
step: 340 , loss: 0.0007440241752192378
0.000770618615206331
step: 350 , loss: 0.0012958431616425514
0.0006644060485996306
step: 360 , loss: 0.0015040236758068204
0.001492563751526177
step: 370 , loss: 0.0007810325478203595
0.0018178647151216865
step: 380 , loss: 0.0009402772993780673
0.0010163369588553905
step: 390 , loss: 0.0005537940887734294
0.0007918378105387092
step: 400 , loss: 0.0012546093203127384
0.0014245305210351944
step: 410 , loss: 0.0007978742942214012
0.0006833180086687207
step: 420 , loss: 0.0012708761496469378
0.0009090130915865302
step: 430 , loss: 0.0008191128727048635
0.000678486016113311
step: 440 , loss: 0.0017246552743017673
0.00220854370854795
step: 450 , loss: 0.001189619884826243
0.0016423948109149933
step: 460 , loss: 0.00038438226329162717
0.0015180424088612199
step: 470 , loss: 0.0016121231019496918
0.0006228976417332888
step: 480 , loss: 0.0009311611065641046
0.001449861447326839
step: 490 , loss: 0.0004470659187063575
0.0006856168620288372
step: 500 , loss: 0.0006819313275627792
0.0019689553882926702
lr: 0.005
activation function type: relu
depth: 2
width: 20
test_loss: 0.001999074127525091
