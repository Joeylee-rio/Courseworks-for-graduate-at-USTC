step: 10 , loss: 0.26832425594329834
0.27989912033081055
step: 20 , loss: 0.1326713114976883
0.1675453931093216
step: 30 , loss: 0.07645533978939056
0.07459558546543121
step: 40 , loss: 0.026115041226148605
0.023966537788510323
step: 50 , loss: 0.013489359058439732
0.011519188061356544
step: 60 , loss: 0.010430694557726383
0.00924458634108305
step: 70 , loss: 0.014074757695198059
0.00911298394203186
step: 80 , loss: 0.003968037199229002
0.007800695952028036
step: 90 , loss: 0.010956626385450363
0.008161821402609348
step: 100 , loss: 0.004935075994580984
0.006836836226284504
step: 110 , loss: 0.005270755849778652
0.005955106113106012
step: 120 , loss: 0.00376751646399498
0.0058607072569429874
step: 130 , loss: 0.0057403105311095715
0.0053266799077391624
step: 140 , loss: 0.004671789705753326
0.005329040344804525
step: 150 , loss: 0.005016684532165527
0.004504827782511711
step: 160 , loss: 0.006271337158977985
0.00517656235024333
step: 170 , loss: 0.005648420192301273
0.0038377672899514437
step: 180 , loss: 0.003394785802811384
0.0037561971694231033
step: 190 , loss: 0.0034650182351469994
0.0038450618740171194
step: 200 , loss: 0.001483279513195157
0.00367519399151206
step: 210 , loss: 0.004054502118378878
0.0033192182891070843
step: 220 , loss: 0.002634570002555847
0.003641947405412793
step: 230 , loss: 0.003544286359101534
0.0034189396537840366
step: 240 , loss: 0.001536856172606349
0.003328870050609112
step: 250 , loss: 0.00532944779843092
0.003520750906318426
step: 260 , loss: 0.0018300447845831513
0.0030270146671682596
step: 270 , loss: 0.002102281665429473
0.0029591727070510387
step: 280 , loss: 0.00269848620519042
0.0028701305855065584
step: 290 , loss: 0.0032617305405437946
0.002862503519281745
step: 300 , loss: 0.004093759227544069
0.0031642229296267033
step: 310 , loss: 0.002152416156604886
0.002912993775680661
step: 320 , loss: 0.0016465886728838086
0.0028484829235821962
step: 330 , loss: 0.00551251508295536
0.0038286393973976374
step: 340 , loss: 0.00375460647046566
0.002752414671704173
step: 350 , loss: 0.003492558840662241
0.00305251800455153
step: 360 , loss: 0.0022266393061727285
0.0027085260953754187
step: 370 , loss: 0.0026034745387732983
0.004234139807522297
step: 380 , loss: 0.008206505328416824
0.0026539424434304237
step: 390 , loss: 0.0024576103314757347
0.0027604519855231047
step: 400 , loss: 0.006504041142761707
0.0032572043128311634
step: 410 , loss: 0.0019436822040006518
0.0027418346144258976
step: 420 , loss: 0.0020859623327851295
0.0032478738576173782
step: 430 , loss: 0.0016723660519346595
0.003517979523167014
step: 440 , loss: 0.0020870650187134743
0.002721182070672512
step: 450 , loss: 0.004645334091037512
0.002771242754533887
step: 460 , loss: 0.0017121664714068174
0.002639328595250845
step: 470 , loss: 0.004877283237874508
0.00265490566380322
step: 480 , loss: 0.0018113481346517801
0.0026179077103734016
step: 490 , loss: 0.0028318362310528755
0.002660794649273157
step: 500 , loss: 0.003985827788710594
0.0028717857785522938
lr: 0.01
activation function type: relu
depth: 4
width: 10
test_loss: 0.0029669401701539755
