0.002513776878247484
(tensor([6.5132], device='cuda:0'), tensor([0.2295], device='cuda:0'))
3500
Net(
  (inp_layer): Linear(in_features=1, out_features=10, bias=True)
  (hiddens): ModuleList(
    (0): Linear(in_features=10, out_features=10, bias=True)
    (1): Linear(in_features=10, out_features=10, bias=True)
    (2): Linear(in_features=10, out_features=10, bias=True)
  )
  (out_layer): Linear(in_features=10, out_features=1, bias=True)
)
step: 10 , loss: 0.0487629659473896
0.028374873101711273
step: 20 , loss: 0.0024127927608788013
0.009346934966742992
step: 30 , loss: 0.003193238750100136
0.0025623852852731943
step: 40 , loss: 0.002131028100848198
0.001662059803493321
step: 50 , loss: 0.0015196031890809536
0.0022396536078304052
step: 60 , loss: 0.0011875100899487734
0.0010416415752843022
step: 70 , loss: 0.0005303550278767943
0.00048144589527510107
step: 80 , loss: 0.0012976210564374924
0.0008491954067721963
step: 90 , loss: 0.002912720898166299
0.002139410236850381
step: 100 , loss: 0.0004955249023623765
0.0008789148996584117
step: 110 , loss: 0.0008860486559569836
0.0005326885147951543
step: 120 , loss: 0.0003008842177223414
0.0004648592439480126
step: 130 , loss: 0.0013641065452247858
0.0006513074622489512
step: 140 , loss: 0.0022659897804260254
0.001780546037480235
step: 150 , loss: 0.0010179068194702268
0.0009394219378009439
step: 160 , loss: 0.0014023493276908994
0.0015229930868372321
step: 170 , loss: 0.0007267569308169186
0.0013268700568005443
step: 180 , loss: 0.0002069564798148349
0.00046561582712456584
step: 190 , loss: 0.00041352686821483076
0.00026694926782511175
step: 200 , loss: 0.000531442288774997
0.0002567809715401381
step: 210 , loss: 0.0002912092604674399
0.0002258044114569202
step: 220 , loss: 0.0006530447863042355
0.00019436061847954988
step: 230 , loss: 0.0004028041730634868
0.00026693198014982045
step: 240 , loss: 0.00026423222152516246
0.0002274481375934556
step: 250 , loss: 0.00031682601547800004
0.0003349030448589474
step: 260 , loss: 0.00015108686056919396
0.0002525649615563452
step: 270 , loss: 0.0008514251094311476
0.0009977661538869143
step: 280 , loss: 0.0007050991989672184
0.00028064436628483236
step: 290 , loss: 0.0012547518126666546
0.003618963761255145
step: 300 , loss: 0.0004956587799824774
0.00035610547638498247
step: 310 , loss: 0.0015519621083512902
0.0005686391377821565
step: 320 , loss: 0.00016451919509563595
0.00017460898379795253
step: 330 , loss: 0.00026424776297062635
0.00027627049712464213
step: 340 , loss: 0.00024688587291166186
0.00018717761849984527
step: 350 , loss: 0.002983059035614133
0.00039079124690033495
step: 360 , loss: 0.0008490558248013258
0.00017611165822017938
step: 370 , loss: 0.00029747249209322035
0.00021480504074133933
step: 380 , loss: 0.00024991380632855
0.0002878303930629045
step: 390 , loss: 0.0005411047604866326
0.00024759999359957874
step: 400 , loss: 0.00047885673120617867
0.00032445485703647137
step: 410 , loss: 0.0003866860643029213
0.00016816002607811242
step: 420 , loss: 0.0003476618730928749
0.0005237186560407281
step: 430 , loss: 0.00044757217983715236
0.0003682741371449083
step: 440 , loss: 0.001840361743234098
0.002077204640954733
step: 450 , loss: 0.0014487089356407523
0.0006009654025547206
step: 460 , loss: 0.0004976632189936936
0.0008397979545406997
step: 470 , loss: 0.00021493564418051392
0.000600707542616874
step: 480 , loss: 0.0001964080147445202
0.0019501530332490802
step: 490 , loss: 0.0005575429531745613
0.00017128225590568036
step: 500 , loss: 0.000535139290150255
0.0005424356204457581
lr: 0.01
activation function type: relu
depth: 4
width: 10
test_loss: 0.0005773521843366325
