Net(
  (inp_layer): Linear(in_features=1, out_features=10, bias=True)
  (hiddens): ModuleList(
    (0): Linear(in_features=10, out_features=10, bias=True)
    (1): Linear(in_features=10, out_features=10, bias=True)
    (2): Linear(in_features=10, out_features=10, bias=True)
  )
  (out_layer): Linear(in_features=10, out_features=1, bias=True)
)
step: 10 , loss: 0.01949739269912243
0.02114015258848667
step: 20 , loss: 0.003538520075380802
0.009107970632612705
step: 30 , loss: 0.00574919767677784
0.008535093627870083
step: 40 , loss: 0.003953925799578428
0.002545502269640565
step: 50 , loss: 0.0048306891694664955
0.0027233297005295753
step: 60 , loss: 0.0012239222414791584
0.0012821027776226401
step: 70 , loss: 0.0019615530036389828
0.0018068508943542838
step: 80 , loss: 0.005008961074054241
0.0009966345969587564
step: 90 , loss: 0.0016422641929239035
0.0009344655554741621
step: 100 , loss: 0.000708147359546274
0.0005972299259155989
step: 110 , loss: 0.0006384479929693043
0.0009112004190683365
step: 120 , loss: 0.001973987789824605
0.0007312315865419805
step: 130 , loss: 0.0011362644145265222
0.0017903803382068872
step: 140 , loss: 0.0022618845105171204
0.002978523029014468
step: 150 , loss: 0.0017891910392791033
0.0013580747181549668
step: 160 , loss: 0.00019838711887132376
0.0003647945122793317
step: 170 , loss: 0.00042052922071889043
0.0004755318514071405
step: 180 , loss: 0.00066189537756145
0.00022601836826652288
step: 190 , loss: 0.0006435452960431576
0.0007077584741637111
step: 200 , loss: 0.00012049228826072067
0.00028813123935833573
step: 210 , loss: 0.0006685105618089437
0.0006706895073875785
step: 220 , loss: 0.0014494829811155796
0.0007903532241471112
step: 230 , loss: 0.0002976920222863555
0.00016469274123664945
step: 240 , loss: 0.00014152334188111126
0.00033576355781406164
step: 250 , loss: 0.00013884346117265522
0.000187262223334983
step: 260 , loss: 0.0002763549564406276
0.000602484040427953
step: 270 , loss: 0.0004923337837681174
0.00018544505292084068
step: 280 , loss: 0.0033089614007622004
0.000637941004242748
step: 290 , loss: 0.00022126325347926468
0.00022210340830497444
step: 300 , loss: 0.0004569752491079271
0.00018384466238785535
step: 310 , loss: 0.00027517491253092885
0.000297361082630232
step: 320 , loss: 0.0001676927786320448
0.00026763821369968355
step: 330 , loss: 0.0001932569284690544
0.00011975048983003944
step: 340 , loss: 0.0003990085097029805
0.0009773061610758305
step: 350 , loss: 0.0002714479633141309
0.00035353723797015846
step: 360 , loss: 0.0008978861733339727
0.0002686298103071749
step: 370 , loss: 0.0002191201492678374
0.0006445283070206642
step: 380 , loss: 0.00023229158250615
0.0004484335076995194
step: 390 , loss: 0.0005530450725927949
0.00032411713618785143
step: 400 , loss: 9.744134149514139e-05
0.00015893355885054916
step: 410 , loss: 7.073130109347403e-05
0.00019726750906556845
step: 420 , loss: 0.0003639484930317849
0.0007349724182859063
step: 430 , loss: 0.00010426310473121703
7.820413884473965e-05
step: 440 , loss: 0.00022103737865108997
0.0001651065977057442
step: 450 , loss: 0.000289454183075577
0.00044204763253219426
step: 460 , loss: 0.0001530734298285097
0.0003066537028644234
step: 470 , loss: 0.0024938243441283703
0.0008434889023192227
step: 480 , loss: 0.0003037317073903978
0.0010367882205173373
step: 490 , loss: 0.00017864667461253703
0.00020471254538279027
step: 500 , loss: 0.00033301932853646576
0.0002995831600856036
lr: 0.01
activation function type: relu
depth: 4
width: 10
test_loss: 0.00030091474764049053
