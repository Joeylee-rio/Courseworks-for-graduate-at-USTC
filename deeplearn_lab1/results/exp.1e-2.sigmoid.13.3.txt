Net(
  (inp_layer): Linear(in_features=1, out_features=13, bias=True)
  (hiddens): ModuleList(
    (0): Linear(in_features=13, out_features=13, bias=True)
    (1): Linear(in_features=13, out_features=13, bias=True)
  )
  (out_layer): Linear(in_features=13, out_features=1, bias=True)
)
step: 10 , loss: 0.4050970673561096
0.35962292551994324
step: 20 , loss: 0.012765332125127316
0.021603884175419807
step: 30 , loss: 0.012407082132995129
0.021480944007635117
step: 40 , loss: 0.019632931798696518
0.019802285358309746
step: 50 , loss: 0.024570725858211517
0.020779946818947792
step: 60 , loss: 0.021134983748197556
0.018893463537096977
step: 70 , loss: 0.012788500636816025
0.01884671300649643
step: 80 , loss: 0.01496716309338808
0.019312258809804916
step: 90 , loss: 0.010007496923208237
0.01937427558004856
step: 100 , loss: 0.015478810295462608
0.018053168430924416
step: 110 , loss: 0.006915531121194363
0.01891106180846691
step: 120 , loss: 0.009634530171751976
0.017582539469003677
step: 130 , loss: 0.012365240603685379
0.018744610249996185
step: 140 , loss: 0.0449407733976841
0.01791238598525524
step: 150 , loss: 0.008468512445688248
0.017491068691015244
step: 160 , loss: 0.022664682939648628
0.018777193501591682
step: 170 , loss: 0.005729467608034611
0.01744781620800495
step: 180 , loss: 0.012832734733819962
0.02094976231455803
step: 190 , loss: 0.01749846339225769
0.0179915651679039
step: 200 , loss: 0.0028862652834504843
0.01741361990571022
step: 210 , loss: 0.003131901379674673
0.017194151878356934
step: 220 , loss: 0.010988658294081688
0.01730477251112461
step: 230 , loss: 0.007587752304971218
0.01895166002213955
step: 240 , loss: 0.01294337771832943
0.0178128220140934
step: 250 , loss: 0.008942356333136559
0.019038883969187737
step: 260 , loss: 0.006155841983854771
0.017257237806916237
step: 270 , loss: 0.04090607538819313
0.017386654391884804
step: 280 , loss: 0.00769745372235775
0.01791672594845295
step: 290 , loss: 0.03541475161910057
0.017571954056620598
step: 300 , loss: 0.01853332482278347
0.017263924703001976
step: 310 , loss: 0.007256903685629368
0.017741959542036057
step: 320 , loss: 0.015574697405099869
0.01737608015537262
step: 330 , loss: 0.024878138676285744
0.017341984435915947
step: 340 , loss: 0.03787912428379059
0.017787203192710876
step: 350 , loss: 0.002587055554613471
0.01729995757341385
step: 360 , loss: 0.012688779272139072
0.018357381224632263
step: 370 , loss: 0.019769124686717987
0.018425680696964264
step: 380 , loss: 0.01874556578695774
0.017303241416811943
step: 390 , loss: 0.006338927894830704
0.017312243580818176
step: 400 , loss: 0.011679431423544884
0.01790495589375496
step: 410 , loss: 0.019194552674889565
0.017510466277599335
step: 420 , loss: 0.02464907243847847
0.01822684332728386
step: 430 , loss: 0.03661476820707321
0.017321566119790077
step: 440 , loss: 0.008059931918978691
0.0171198770403862
step: 450 , loss: 0.0081800427287817
0.017321176826953888
step: 460 , loss: 0.015850797295570374
0.01818680204451084
step: 470 , loss: 0.013699812814593315
0.016414839774370193
step: 480 , loss: 0.0183329526335001
0.016348132863640785
step: 490 , loss: 0.016992243006825447
0.016071386635303497
step: 500 , loss: 0.0404154472053051
0.0160890594124794
lr: 0.01
activation function type: sigmoid
depth: 3
width: 13
test_loss: 0.0176285021007061
