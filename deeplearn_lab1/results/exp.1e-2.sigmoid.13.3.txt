0.002513776878247484
(tensor([6.5132], device='cuda:0'), tensor([0.2295], device='cuda:0'))
3500
Net(
  (inp_layer): Linear(in_features=1, out_features=13, bias=True)
  (hiddens): ModuleList(
    (0): Linear(in_features=13, out_features=13, bias=True)
    (1): Linear(in_features=13, out_features=13, bias=True)
  )
  (out_layer): Linear(in_features=13, out_features=1, bias=True)
)
step: 10 , loss: 0.3679705262184143
0.3290388286113739
step: 20 , loss: 0.39116954803466797
0.32539522647857666
step: 30 , loss: 0.25347331166267395
0.2519975006580353
step: 40 , loss: 0.04044254869222641
0.0217744167894125
step: 50 , loss: 0.01643797568976879
0.021525248885154724
step: 60 , loss: 0.011810633353888988
0.020607979968190193
step: 70 , loss: 0.024595603346824646
0.019587229937314987
step: 80 , loss: 0.0102117620408535
0.01977280154824257
step: 90 , loss: 0.012346371077001095
0.019161203876137733
step: 100 , loss: 0.018201246857643127
0.018918374553322792
step: 110 , loss: 0.011851102113723755
0.018731603398919106
step: 120 , loss: 0.03151656314730644
0.018627554178237915
step: 130 , loss: 0.03486208990216255
0.018470220267772675
step: 140 , loss: 0.0137436268851161
0.018406637012958527
step: 150 , loss: 0.021583862602710724
0.01818225160241127
step: 160 , loss: 0.013473913073539734
0.01864037476480007
step: 170 , loss: 0.014171909540891647
0.017890315502882004
step: 180 , loss: 0.016407640650868416
0.01792042702436447
step: 190 , loss: 0.004757488612085581
0.01812945492565632
step: 200 , loss: 0.023712625727057457
0.018019529059529305
step: 210 , loss: 0.017154041677713394
0.018610956147313118
step: 220 , loss: 0.024258939549326897
0.018034908920526505
step: 230 , loss: 0.014794927090406418
0.01802029274404049
step: 240 , loss: 0.020412007346749306
0.018189188092947006
step: 250 , loss: 0.025781312957406044
0.017817655578255653
step: 260 , loss: 0.02793862670660019
0.018105171620845795
step: 270 , loss: 0.012835917994379997
0.019352231174707413
step: 280 , loss: 0.03386661410331726
0.017950495705008507
step: 290 , loss: 0.007068853825330734
0.01827564649283886
step: 300 , loss: 0.004544724244624376
0.018112417310476303
step: 310 , loss: 0.01546767633408308
0.018386103212833405
step: 320 , loss: 0.013930050656199455
0.01777728646993637
step: 330 , loss: 0.022941092029213905
0.018461737781763077
step: 340 , loss: 0.04045527055859566
0.017823297530412674
step: 350 , loss: 0.00980061013251543
0.017927777022123337
step: 360 , loss: 0.016199329867959023
0.0185127854347229
step: 370 , loss: 0.027460888028144836
0.01791558787226677
step: 380 , loss: 0.007948664017021656
0.017837993800640106
step: 390 , loss: 0.02329855225980282
0.017711345106363297
step: 400 , loss: 0.02825457789003849
0.017908640205860138
step: 410 , loss: 0.014382327906787395
0.01814109832048416
step: 420 , loss: 0.008457861840724945
0.017968960106372833
step: 430 , loss: 0.013575352728366852
0.018003832548856735
step: 440 , loss: 0.012458821758627892
0.017754042521119118
step: 450 , loss: 0.01935156248509884
0.017790203914046288
step: 460 , loss: 0.013065187260508537
0.018129320815205574
step: 470 , loss: 0.028747722506523132
0.017643410712480545
step: 480 , loss: 0.019335905089974403
0.018531829118728638
step: 490 , loss: 0.011749961413443089
0.018482016399502754
step: 500 , loss: 0.02104036509990692
0.017765870317816734
lr: 0.01
activation function type: sigmoid
depth: 3
width: 13
test_loss: 0.01698843203485012
