0.002513776878247484
(tensor([6.5132], device='cuda:0'), tensor([0.2295], device='cuda:0'))
3500
Net(
  (inp_layer): Linear(in_features=1, out_features=10, bias=True)
  (hiddens): ModuleList(
    (0): Linear(in_features=10, out_features=10, bias=True)
    (1): Linear(in_features=10, out_features=10, bias=True)
    (2): Linear(in_features=10, out_features=10, bias=True)
  )
  (out_layer): Linear(in_features=10, out_features=1, bias=True)
)
step: 10 , loss: 0.35341909527778625
0.3336462080478668
step: 20 , loss: 0.42917102575302124
0.2730901539325714
step: 30 , loss: 0.1329479217529297
0.14539578557014465
step: 40 , loss: 0.057498686015605927
0.05568038299679756
step: 50 , loss: 0.042968835681676865
0.03312031924724579
step: 60 , loss: 0.020329101011157036
0.021686187013983727
step: 70 , loss: 0.012222694233059883
0.010210353881120682
step: 80 , loss: 0.006481129676103592
0.005594097543507814
step: 90 , loss: 0.003973686136305332
0.004017445724457502
step: 100 , loss: 0.0037007431965321302
0.0031066297087818384
step: 110 , loss: 0.01027582585811615
0.01745697855949402
step: 120 , loss: 0.001413604593835771
0.0034783794544637203
step: 130 , loss: 0.0022379811853170395
0.0020818770863115788
step: 140 , loss: 0.001653364161029458
0.0018818387761712074
step: 150 , loss: 0.001408971264027059
0.0014688711380586028
step: 160 , loss: 0.0019083020742982626
0.0016173660987988114
step: 170 , loss: 0.0014399386709555984
0.0014152039075270295
step: 180 , loss: 0.0018273753812536597
0.0018860555719584227
step: 190 , loss: 0.001026585348881781
0.0012317420914769173
step: 200 , loss: 0.0012272004969418049
0.0038929732982069254
step: 210 , loss: 0.0012372946366667747
0.0010107624111697078
step: 220 , loss: 0.0008248368976637721
0.0011318534379824996
step: 230 , loss: 0.0011107473401352763
0.00118548353202641
step: 240 , loss: 0.0002726293751038611
0.0013017588062211871
step: 250 , loss: 0.0004112753667868674
0.000294731929898262
step: 260 , loss: 0.00019389230874367058
0.00021769182058051229
step: 270 , loss: 0.00034973458969034255
0.0012618133332580328
step: 280 , loss: 0.0003413817612454295
0.00017501581169199198
step: 290 , loss: 0.0002063932770397514
0.00024058902636170387
step: 300 , loss: 0.0003280375385656953
0.0002309128612978384
step: 310 , loss: 0.001236913027241826
0.0021003817673772573
step: 320 , loss: 0.0001655756204854697
0.00015289847215171903
step: 330 , loss: 0.0001637647656025365
0.00047632810310460627
step: 340 , loss: 0.0004174189525656402
0.018924934789538383
step: 350 , loss: 0.00012207849067635834
0.00015481634181924164
step: 360 , loss: 0.0006932643591426313
0.0001723651512293145
step: 370 , loss: 0.0002742146607488394
0.0006694114999845624
step: 380 , loss: 0.000153024448081851
0.0006208539707586169
step: 390 , loss: 0.0002730214619077742
0.0002070315822493285
step: 400 , loss: 0.0001638744433876127
0.0006300150416791439
step: 410 , loss: 0.00024658339680172503
0.00030853875796310604
step: 420 , loss: 0.0015552545664831996
0.0007380288443528116
step: 430 , loss: 0.00047067206469364464
0.00022506849199999124
step: 440 , loss: 0.00026399351190775633
0.00032540762913413346
step: 450 , loss: 0.00021083044703118503
0.00034557291655801237
step: 460 , loss: 0.0002750012499745935
0.00016370834782719612
step: 470 , loss: 0.0009745752322487533
0.000990847242064774
step: 480 , loss: 0.0006738590891472995
0.0003732222248800099
step: 490 , loss: 0.0006054284167475998
0.0010298959678038955
step: 500 , loss: 0.0001827559754019603
0.00020433735335245728
lr: 0.001
activation function type: tanh
depth: 4
width: 10
test_loss: 0.00020007511193398386
