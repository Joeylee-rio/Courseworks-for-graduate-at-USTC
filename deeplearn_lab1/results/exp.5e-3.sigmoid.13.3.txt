Net(
  (inp_layer): Linear(in_features=1, out_features=13, bias=True)
  (hiddens): ModuleList(
    (0): Linear(in_features=13, out_features=13, bias=True)
    (1): Linear(in_features=13, out_features=13, bias=True)
  )
  (out_layer): Linear(in_features=13, out_features=1, bias=True)
)
step: 10 , loss: 0.3969074487686157
0.35806384682655334
step: 20 , loss: 0.4163057208061218
0.27275151014328003
step: 30 , loss: 0.013804825022816658
0.02411460690200329
step: 40 , loss: 0.019948236644268036
0.020832516252994537
step: 50 , loss: 0.029189512133598328
0.019397662952542305
step: 60 , loss: 0.0205671489238739
0.018823204562067986
step: 70 , loss: 0.012364311143755913
0.01881950907409191
step: 80 , loss: 0.015396401286125183
0.018074721097946167
step: 90 , loss: 0.010459096170961857
0.018775712698698044
step: 100 , loss: 0.014158343896269798
0.017696255818009377
step: 110 , loss: 0.0063613043166697025
0.017282385379076004
step: 120 , loss: 0.009264174848794937
0.016554241999983788
step: 130 , loss: 0.011730952188372612
0.016681397333741188
step: 140 , loss: 0.043416328728199005
0.016749579459428787
step: 150 , loss: 0.006606243550777435
0.016674980521202087
step: 160 , loss: 0.019887935370206833
0.017171330749988556
step: 170 , loss: 0.0047573521733284
0.016383295878767967
step: 180 , loss: 0.011612939648330212
0.01853587105870247
step: 190 , loss: 0.01675797998905182
0.01680835336446762
step: 200 , loss: 0.0013049410190433264
0.01650107279419899
step: 210 , loss: 0.0027415668591856956
0.016422001644968987
step: 220 , loss: 0.011050136759877205
0.016199853271245956
step: 230 , loss: 0.00658999290317297
0.017526153475046158
step: 240 , loss: 0.009340937249362469
0.01655394770205021
step: 250 , loss: 0.007576535455882549
0.017158588394522667
step: 260 , loss: 0.005765518173575401
0.0163703802973032
step: 270 , loss: 0.03913529962301254
0.016398591920733452
step: 280 , loss: 0.006099814549088478
0.016771724447607994
step: 290 , loss: 0.03389142453670502
0.016254540532827377
step: 300 , loss: 0.01799137517809868
0.01610511541366577
step: 310 , loss: 0.005611517932265997
0.016622740775346756
step: 320 , loss: 0.01507725939154625
0.01649753749370575
step: 330 , loss: 0.024019166827201843
0.016180865466594696
step: 340 , loss: 0.0353727750480175
0.016220493242144585
step: 350 , loss: 0.001995517173781991
0.01637151651084423
step: 360 , loss: 0.008761562407016754
0.016359703615307808
step: 370 , loss: 0.019154595211148262
0.01675294153392315
step: 380 , loss: 0.017223291099071503
0.016569513827562332
step: 390 , loss: 0.004931659437716007
0.016413291916251183
step: 400 , loss: 0.008955419063568115
0.016501696780323982
step: 410 , loss: 0.01620468869805336
0.016270603984594345
step: 420 , loss: 0.022939834743738174
0.01658467762172222
step: 430 , loss: 0.03784959763288498
0.01660882867872715
step: 440 , loss: 0.007434831466525793
0.016118906438350677
step: 450 , loss: 0.006438300479203463
0.016159573569893837
step: 460 , loss: 0.013110377825796604
0.016848623752593994
step: 470 , loss: 0.01357056014239788
0.016126183792948723
step: 480 , loss: 0.018046148121356964
0.01613793522119522
step: 490 , loss: 0.016847750172019005
0.01611536368727684
step: 500 , loss: 0.03900308161973953
0.01603551208972931
lr: 0.005
activation function type: sigmoid
depth: 3
width: 13
test_loss: 0.01753559336066246
