Net(
  (inp_layer): Linear(in_features=1, out_features=20, bias=True)
  (hiddens): ModuleList(
    (0): Linear(in_features=20, out_features=20, bias=True)
  )
  (out_layer): Linear(in_features=20, out_features=1, bias=True)
)
step: 10 , loss: 0.4364762008190155
0.3540365397930145
step: 20 , loss: 0.28411930799484253
0.29109010100364685
step: 30 , loss: 0.22698336839675903
0.1884372979402542
step: 40 , loss: 0.13941392302513123
0.12530864775180817
step: 50 , loss: 0.0864071249961853
0.10697333514690399
step: 60 , loss: 0.11386267095804214
0.09618886560201645
step: 70 , loss: 0.06983549147844315
0.09045006334781647
step: 80 , loss: 0.02282450720667839
0.08247552812099457
step: 90 , loss: 0.08603781461715698
0.07750730216503143
step: 100 , loss: 0.07553477585315704
0.06955379247665405
step: 110 , loss: 0.0854974091053009
0.061462048441171646
step: 120 , loss: 0.06868675351142883
0.05278930068016052
step: 130 , loss: 0.05769668519496918
0.0438370555639267
step: 140 , loss: 0.05882657691836357
0.03534993901848793
step: 150 , loss: 0.02685583010315895
0.027192194014787674
step: 160 , loss: 0.015576994977891445
0.018773136660456657
step: 170 , loss: 0.003129189368337393
0.013616182841360569
step: 180 , loss: 0.012554557994008064
0.010317091830074787
step: 190 , loss: 0.0015136853326112032
0.008320827968418598
step: 200 , loss: 0.006592500954866409
0.007006299681961536
step: 210 , loss: 0.0021827570162713528
0.00585728045552969
step: 220 , loss: 0.004703426733613014
0.004814964719116688
step: 230 , loss: 0.0031213632319122553
0.004398743622004986
step: 240 , loss: 0.0015057014534249902
0.003426759038120508
step: 250 , loss: 0.0030083227902650833
0.003207650501281023
step: 260 , loss: 0.002776445122435689
0.0019440463511273265
step: 270 , loss: 0.0021544937044382095
0.0015247927512973547
step: 280 , loss: 0.0005266875959932804
0.0010543783428147435
step: 290 , loss: 0.00047901360085234046
0.0008198068244382739
step: 300 , loss: 0.00013483306975103915
0.0005127655458636582
step: 310 , loss: 0.0005191238014958799
0.000408084160881117
step: 320 , loss: 0.0005250885151326656
0.0002502834249753505
step: 330 , loss: 0.00019378331489861012
0.00021177709277253598
step: 340 , loss: 0.0002767316182143986
0.00023641428560949862
step: 350 , loss: 0.0003464012697804719
0.0001819331373553723
step: 360 , loss: 0.0003215174947399646
0.00020923624106217176
step: 370 , loss: 0.00016664667055010796
0.00019254595099482685
step: 380 , loss: 0.00013078644406050444
0.00014774555165786296
step: 390 , loss: 0.00012049909855704755
8.889001765055582e-05
step: 400 , loss: 0.00011497977538965642
9.29502712097019e-05
step: 410 , loss: 0.00010146947170142084
7.183520210674033e-05
step: 420 , loss: 4.816451109945774e-05
6.584189395653084e-05
step: 430 , loss: 5.975774547550827e-05
6.11191353527829e-05
step: 440 , loss: 0.00012728777073789388
7.52294363337569e-05
step: 450 , loss: 3.067137731704861e-05
6.281901733018458e-05
step: 460 , loss: 2.8754289814969525e-05
5.0932212616316974e-05
step: 470 , loss: 6.190838757902384e-05
6.737120565958321e-05
step: 480 , loss: 6.635433237534016e-05
6.612377183046192e-05
step: 490 , loss: 0.00013506256800610572
3.562704296200536e-05
step: 500 , loss: 3.885092883137986e-05
6.574371946044266e-05
lr: 0.0005
activation function type: tanh
depth: 2
width: 20
test_loss: 6.767108425265178e-05
