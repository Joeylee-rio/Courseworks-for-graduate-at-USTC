step: 10 , loss: 0.47183552384376526
0.3846225142478943
step: 20 , loss: 0.3539189100265503
0.3626188039779663
step: 30 , loss: 0.39739471673965454
0.35034093260765076
step: 40 , loss: 0.3375304341316223
0.3328966200351715
step: 50 , loss: 0.255548894405365
0.3129110038280487
step: 60 , loss: 0.32915812730789185
0.2899149954319
step: 70 , loss: 0.2666122615337372
0.2628064453601837
step: 80 , loss: 0.16767802834510803
0.2297765612602234
step: 90 , loss: 0.22286878526210785
0.19591256976127625
step: 100 , loss: 0.16719016432762146
0.16693498194217682
step: 110 , loss: 0.18456992506980896
0.14133694767951965
step: 120 , loss: 0.17631876468658447
0.12010225653648376
step: 130 , loss: 0.15830518305301666
0.10230454057455063
step: 140 , loss: 0.1077314168214798
0.08858106285333633
step: 150 , loss: 0.0730239599943161
0.07963871955871582
step: 160 , loss: 0.06684300303459167
0.0729031190276146
step: 170 , loss: 0.03844260424375534
0.06695500761270523
step: 180 , loss: 0.07249237596988678
0.06371282041072845
step: 190 , loss: 0.03625256568193436
0.05893128365278244
step: 200 , loss: 0.03816160187125206
0.05585331842303276
step: 210 , loss: 0.0410887636244297
0.052949000149965286
step: 220 , loss: 0.05009300634264946
0.050864361226558685
step: 230 , loss: 0.03126130998134613
0.048291370272636414
step: 240 , loss: 0.015350433066487312
0.04633352532982826
step: 250 , loss: 0.027863023802638054
0.04470779001712799
step: 260 , loss: 0.0688600018620491
0.04316820204257965
step: 270 , loss: 0.07336055487394333
0.04146580770611763
step: 280 , loss: 0.03314618766307831
0.040346428751945496
step: 290 , loss: 0.0313093401491642
0.03885190561413765
step: 300 , loss: 0.02482597529888153
0.03754058852791786
step: 310 , loss: 0.040922194719314575
0.036535002291202545
step: 320 , loss: 0.02120177447795868
0.03525214642286301
step: 330 , loss: 0.013635972514748573
0.03444208577275276
step: 340 , loss: 0.017605207860469818
0.03399422764778137
step: 350 , loss: 0.06174284219741821
0.03221415728330612
step: 360 , loss: 0.020846020430326462
0.03144172579050064
step: 370 , loss: 0.02886863425374031
0.030346093699336052
step: 380 , loss: 0.03681868687272072
0.02926037088036537
step: 390 , loss: 0.04137800261378288
0.02798047848045826
step: 400 , loss: 0.024566909298300743
0.026299675926566124
step: 410 , loss: 0.019163791090250015
0.024427374824881554
step: 420 , loss: 0.01775228977203369
0.02221374586224556
step: 430 , loss: 0.014223771169781685
0.020927639678120613
step: 440 , loss: 0.030455147847533226
0.01961570419371128
step: 450 , loss: 0.018171072006225586
0.018707310780882835
step: 460 , loss: 0.01705821044743061
0.017689671367406845
step: 470 , loss: 0.006122141145169735
0.016867494210600853
step: 480 , loss: 0.00546268280595541
0.016030171886086464
step: 490 , loss: 0.009803028777241707
0.015438632108271122
step: 500 , loss: 0.003720085136592388
0.01454913429915905
lr: 0.0005
activation function type: tanh
depth: 2
width: 20
test_loss: 0.015547264367341995
