0.002513776878247484
(tensor([6.5132], device='cuda:0'), tensor([0.2295], device='cuda:0'))
3500
Net(
  (inp_layer): Linear(in_features=1, out_features=10, bias=True)
  (hiddens): ModuleList(
    (0): Linear(in_features=10, out_features=10, bias=True)
    (1): Linear(in_features=10, out_features=10, bias=True)
    (2): Linear(in_features=10, out_features=10, bias=True)
  )
  (out_layer): Linear(in_features=10, out_features=1, bias=True)
)
step: 10 , loss: 0.35555633902549744
0.34142476320266724
step: 20 , loss: 0.5089406967163086
0.3339042067527771
step: 30 , loss: 0.4196597933769226
0.3154684901237488
step: 40 , loss: 0.2684682011604309
0.22580023109912872
step: 50 , loss: 0.1331159770488739
0.14792394638061523
step: 60 , loss: 0.0813722237944603
0.10870222747325897
step: 70 , loss: 0.06015295907855034
0.06198136880993843
step: 80 , loss: 0.03697619587182999
0.03559485450387001
step: 90 , loss: 0.020209161564707756
0.01722724549472332
step: 100 , loss: 0.008225370198488235
0.012175709009170532
step: 110 , loss: 0.01282636821269989
0.00989972148090601
step: 120 , loss: 0.005419458262622356
0.008110024966299534
step: 130 , loss: 0.007692868355661631
0.009093045257031918
step: 140 , loss: 0.006399262696504593
0.005818674806505442
step: 150 , loss: 0.003741389838978648
0.0049017625860869884
step: 160 , loss: 0.002761022886261344
0.0026378233451396227
step: 170 , loss: 0.001161239924840629
0.0022938037291169167
step: 180 , loss: 0.001729682320728898
0.0030407060403376818
step: 190 , loss: 0.0010357514256611466
0.0014203975442796946
step: 200 , loss: 0.0006144627695903182
0.0012857767287641764
step: 210 , loss: 0.0014102638233453035
0.0011323611252009869
step: 220 , loss: 0.001083860290236771
0.001120308879762888
step: 230 , loss: 0.001650471007451415
0.001083124428987503
step: 240 , loss: 0.0015343079576268792
0.0011968245962634683
step: 250 , loss: 0.0016304767923429608
0.0013048956170678139
step: 260 , loss: 0.001160991727374494
0.0012605568626895547
step: 270 , loss: 0.0017455484485253692
0.002194924047216773
step: 280 , loss: 0.00035674023092724383
0.0009172371355816722
step: 290 , loss: 0.002129562431946397
0.0013408816885203123
step: 300 , loss: 0.0016023429343476892
0.0008068405441008508
step: 310 , loss: 0.0010978009086102247
0.0006661365041509271
step: 320 , loss: 0.0005828283028677106
0.0005214885459281504
step: 330 , loss: 0.0003201458603143692
0.0009816073579713702
step: 340 , loss: 0.00037504290230572224
0.002558057429268956
step: 350 , loss: 9.597893222235143e-05
0.00016543471429031342
step: 360 , loss: 8.275916479760781e-05
0.00021148915402591228
step: 370 , loss: 0.00011229173833271489
0.0001294655812671408
step: 380 , loss: 0.00023198462440632284
0.00012122641055611894
step: 390 , loss: 7.813628326402977e-05
0.00032579261460341513
step: 400 , loss: 0.0004393136769067496
0.00029006722616031766
step: 410 , loss: 0.00011423886462580413
0.00014028158329892904
step: 420 , loss: 7.468090916518122e-05
0.00026254929252900183
step: 430 , loss: 0.000164335360750556
0.00012756483920384198
step: 440 , loss: 0.00010628595191519707
0.00010914323502220213
step: 450 , loss: 0.00027069152565672994
0.00010324545291950926
step: 460 , loss: 0.0002819485089275986
0.0011902444530278444
step: 470 , loss: 0.0005995099782012403
0.0005711768171750009
step: 480 , loss: 7.990242738742381e-05
7.725611794739962e-05
step: 490 , loss: 0.00044512140448205173
0.0009094959823414683
step: 500 , loss: 6.599032349186018e-05
9.654055611463264e-05
lr: 0.0005
activation function type: tanh
depth: 4
width: 10
test_loss: 8.720036566955969e-05
