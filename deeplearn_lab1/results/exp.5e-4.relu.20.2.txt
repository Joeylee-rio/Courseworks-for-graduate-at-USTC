step: 10 , loss: 0.5806242823600769
0.4471305012702942
step: 20 , loss: 0.3958335518836975
0.38846826553344727
step: 30 , loss: 0.3273308277130127
0.3518073260784149
step: 40 , loss: 0.2753280997276306
0.31311318278312683
step: 50 , loss: 0.20208972692489624
0.2677334249019623
step: 60 , loss: 0.26673415303230286
0.23092105984687805
step: 70 , loss: 0.2160612940788269
0.19673307240009308
step: 80 , loss: 0.13550806045532227
0.16675586998462677
step: 90 , loss: 0.13805784285068512
0.14210011065006256
step: 100 , loss: 0.12346385419368744
0.12288891524076462
step: 110 , loss: 0.12274518609046936
0.10243646800518036
step: 120 , loss: 0.11925052851438522
0.0895395427942276
step: 130 , loss: 0.09772127866744995
0.08163933455944061
step: 140 , loss: 0.11104324460029602
0.07364439964294434
step: 150 , loss: 0.05964589864015579
0.06928912550210953
step: 160 , loss: 0.061013322323560715
0.06580044329166412
step: 170 , loss: 0.028849374502897263
0.06321004778146744
step: 180 , loss: 0.07864496856927872
0.06277620047330856
step: 190 , loss: 0.02603902854025364
0.05947534739971161
step: 200 , loss: 0.036992236971855164
0.058171533048152924
step: 210 , loss: 0.041441723704338074
0.05692131072282791
step: 220 , loss: 0.055539682507514954
0.05646725744009018
step: 230 , loss: 0.03543753921985626
0.05489837005734444
step: 240 , loss: 0.014112170785665512
0.05369396507740021
step: 250 , loss: 0.030255381017923355
0.05290824547410011
step: 260 , loss: 0.08477075397968292
0.05218365788459778
step: 270 , loss: 0.08971133828163147
0.05085214599967003
step: 280 , loss: 0.03891407698392868
0.0500665158033371
step: 290 , loss: 0.03846873342990875
0.049268946051597595
step: 300 , loss: 0.032237641513347626
0.04841361567378044
step: 310 , loss: 0.052649665623903275
0.04787929728627205
step: 320 , loss: 0.027170980349183083
0.04704820364713669
step: 330 , loss: 0.01743488758802414
0.04585013911128044
step: 340 , loss: 0.025213079527020454
0.04638272151350975
step: 350 , loss: 0.08244170248508453
0.04426836967468262
step: 360 , loss: 0.028117012232542038
0.0435112901031971
step: 370 , loss: 0.039450157433748245
0.0426817424595356
step: 380 , loss: 0.050898998975753784
0.041849762201309204
step: 390 , loss: 0.06294706463813782
0.04159139469265938
step: 400 , loss: 0.03691971302032471
0.040244340896606445
step: 410 , loss: 0.03140275925397873
0.0399269238114357
step: 420 , loss: 0.031473249197006226
0.03847072646021843
step: 430 , loss: 0.025433097034692764
0.03767704218626022
step: 440 , loss: 0.057814810425043106
0.03679864853620529
step: 450 , loss: 0.03615248203277588
0.03661089390516281
step: 460 , loss: 0.03359640762209892
0.03515825793147087
step: 470 , loss: 0.009540091268718243
0.034418560564517975
step: 480 , loss: 0.010123339481651783
0.03429935500025749
step: 490 , loss: 0.020574679598212242
0.03265451267361641
step: 500 , loss: 0.011157866567373276
0.031768471002578735
lr: 0.0005
activation function type: relu
depth: 2
width: 20
test_loss: 0.03387468680739403
