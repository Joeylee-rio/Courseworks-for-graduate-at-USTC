Net(
  (inp_layer): Linear(in_features=1, out_features=20, bias=True)
  (hiddens): ModuleList(
    (0): Linear(in_features=20, out_features=20, bias=True)
  )
  (out_layer): Linear(in_features=20, out_features=1, bias=True)
)
step: 10 , loss: 0.4155028760433197
0.3260020911693573
step: 20 , loss: 0.18061363697052002
0.1836974024772644
step: 30 , loss: 0.07002928853034973
0.06690237671136856
step: 40 , loss: 0.05049516260623932
0.039050981402397156
step: 50 , loss: 0.019306227564811707
0.033008940517902374
step: 60 , loss: 0.040391821414232254
0.029307207092642784
step: 70 , loss: 0.01532400120049715
0.02668486163020134
step: 80 , loss: 0.007504330016672611
0.024809136986732483
step: 90 , loss: 0.024961911141872406
0.02122819609940052
step: 100 , loss: 0.022823957726359367
0.019491448998451233
step: 110 , loss: 0.022064991295337677
0.016743894666433334
step: 120 , loss: 0.01741614192724228
0.01575906202197075
step: 130 , loss: 0.019343364983797073
0.013528130017220974
step: 140 , loss: 0.022711969912052155
0.011126370169222355
step: 150 , loss: 0.009595455601811409
0.009668422862887383
step: 160 , loss: 0.0075517878867685795
0.008053197525441647
step: 170 , loss: 0.001087425509467721
0.006770441308617592
step: 180 , loss: 0.006567417643964291
0.005988562945276499
step: 190 , loss: 0.00039041374111548066
0.004863793030381203
step: 200 , loss: 0.0052798655815422535
0.004568496719002724
step: 210 , loss: 0.0005180751904845238
0.0035112807527184486
step: 220 , loss: 0.0031010527163743973
0.00299617531709373
step: 230 , loss: 0.0009334611822851002
0.0024781576357781887
step: 240 , loss: 0.0002654273994266987
0.0021888704504817724
step: 250 , loss: 0.0012506907805800438
0.002406476764008403
step: 260 , loss: 0.0021538857836276293
0.0014538929099217057
step: 270 , loss: 0.002993362257257104
0.0013562210369855165
step: 280 , loss: 0.001312606269493699
0.0013663069112226367
step: 290 , loss: 0.0007054276065900922
0.0009689361322671175
step: 300 , loss: 0.0004938336205668747
0.0010817310540005565
step: 310 , loss: 0.0013150423765182495
0.001086863107047975
step: 320 , loss: 0.0008801595540717244
0.0010652290657162666
step: 330 , loss: 0.00043905037455260754
0.0006545964279212058
step: 340 , loss: 0.0010756347328424454
0.0009387659374624491
step: 350 , loss: 0.0013130784500390291
0.0005292883142828941
step: 360 , loss: 0.0011820251820608974
0.0006240246002562344
step: 370 , loss: 0.0007561922539025545
0.0005398552748374641
step: 380 , loss: 0.0005157905397936702
0.00045444961870089173
step: 390 , loss: 0.0004290117067284882
0.00048329727724194527
step: 400 , loss: 0.00019861456530634314
0.00044792654807679355
step: 410 , loss: 0.0013671653578057885
0.00041300427983514965
step: 420 , loss: 0.001140944892540574
0.0010171103058382869
step: 430 , loss: 0.00046751482295803726
0.00046298603410832584
step: 440 , loss: 0.0007123421528376639
0.0004141813260503113
step: 450 , loss: 0.0003565233200788498
0.0004480566130951047
step: 460 , loss: 0.000418329902458936
0.00041674156091175973
step: 470 , loss: 0.00046173002920113504
0.0007218780228868127
step: 480 , loss: 0.00034080087789334357
0.0003680755035020411
step: 490 , loss: 0.00037039301241748035
0.0004081079096067697
step: 500 , loss: 0.00034758419496938586
0.00037141251959837973
lr: 0.0005
activation function type: relu
depth: 2
width: 20
test_loss: 0.00039497093530371785
