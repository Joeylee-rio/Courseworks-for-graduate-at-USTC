0.002513776878247484
(tensor([6.5132], device='cuda:0'), tensor([0.2295], device='cuda:0'))
3500
Net(
  (inp_layer): Linear(in_features=1, out_features=20, bias=True)
  (hiddens): ModuleList(
    (0): Linear(in_features=20, out_features=20, bias=True)
  )
  (out_layer): Linear(in_features=20, out_features=1, bias=True)
)
step: 10 , loss: 0.43055790662765503
0.34840941429138184
step: 20 , loss: 0.31570741534233093
0.327264666557312
step: 30 , loss: 0.17439551651477814
0.1911315619945526
step: 40 , loss: 0.1611853688955307
0.12231030315160751
step: 50 , loss: 0.12519174814224243
0.10533615201711655
step: 60 , loss: 0.09045591205358505
0.08685581386089325
step: 70 , loss: 0.059581052511930466
0.1069302037358284
step: 80 , loss: 0.06794723868370056
0.07372678816318512
step: 90 , loss: 0.034141656011343
0.06744075566530228
step: 100 , loss: 0.06132439151406288
0.05870211124420166
step: 110 , loss: 0.04906754568219185
0.05673697963356972
step: 120 , loss: 0.05580649897456169
0.05382952839136124
step: 130 , loss: 0.03325263038277626
0.05125352367758751
step: 140 , loss: 0.0413893461227417
0.05066436156630516
step: 150 , loss: 0.04231885075569153
0.048904694616794586
step: 160 , loss: 0.024332867935299873
0.049367692321538925
step: 170 , loss: 0.0231325626373291
0.04739747941493988
step: 180 , loss: 0.050179582089185715
0.0480852946639061
step: 190 , loss: 0.02762092649936676
0.045338306576013565
step: 200 , loss: 0.019311653450131416
0.0447717122733593
step: 210 , loss: 0.055394336581230164
0.043683286756277084
step: 220 , loss: 0.04156392440199852
0.04692081734538078
step: 230 , loss: 0.02224573865532875
0.04121062159538269
step: 240 , loss: 0.04488792642951012
0.04135585576295853
step: 250 , loss: 0.034536272287368774
0.03857025131583214
step: 260 , loss: 0.019646216183900833
0.032560016959905624
step: 270 , loss: 0.018038034439086914
0.025266138836741447
step: 280 , loss: 0.024861356243491173
0.01900521293282509
step: 290 , loss: 0.01335945725440979
0.014608286321163177
step: 300 , loss: 0.008289271034300327
0.007398118264973164
step: 310 , loss: 0.008071381598711014
0.004038327373564243
step: 320 , loss: 0.0037130191922187805
0.002401141682639718
step: 330 , loss: 0.00126181379891932
0.0017574687954038382
step: 340 , loss: 0.0008251824183389544
0.0007756163249723613
step: 350 , loss: 0.0004187647136859596
0.00046660375664941967
step: 360 , loss: 0.00019417254952713847
0.00021903379820287228
step: 370 , loss: 0.00012714490003418177
0.00017963099526241422
step: 380 , loss: 9.251771552953869e-05
0.00013927761756349355
step: 390 , loss: 5.932554631726816e-05
5.977206819807179e-05
step: 400 , loss: 6.328077870421112e-05
4.266285031917505e-05
step: 410 , loss: 8.32886144053191e-05
4.0745875594438985e-05
step: 420 , loss: 0.000101260251540225
9.908505307976156e-05
step: 430 , loss: 5.717662497772835e-05
5.061272895545699e-05
step: 440 , loss: 2.4438355467282236e-05
1.4011432540428359e-05
step: 450 , loss: 2.1447980543598533e-05
2.1824618670507334e-05
step: 460 , loss: 4.03756566811353e-05
1.41386235554819e-05
step: 470 , loss: 2.480095463397447e-05
2.454133027640637e-05
step: 480 , loss: 8.690409231348895e-06
2.9448581699398346e-05
step: 490 , loss: 7.170440221671015e-05
7.838625606382266e-05
step: 500 , loss: 6.627194579778006e-06
2.8221011234563775e-05
lr: 0.001
activation function type: tanh
depth: 2
width: 20
test_loss: 2.5876764993881807e-05
