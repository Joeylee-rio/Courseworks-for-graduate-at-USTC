Net(
  (inp_layer): Linear(in_features=1, out_features=20, bias=True)
  (hiddens): ModuleList(
    (0): Linear(in_features=20, out_features=20, bias=True)
  )
  (out_layer): Linear(in_features=20, out_features=1, bias=True)
)
step: 10 , loss: 0.04988320916891098
0.059719715267419815
step: 20 , loss: 0.02882952056825161
0.01945851743221283
step: 30 , loss: 0.0015970245003700256
0.0046691857278347015
step: 40 , loss: 0.0009716111235320568
0.0006115398718975484
step: 50 , loss: 0.0027467322070151567
0.000919417361728847
step: 60 , loss: 0.004133207723498344
0.001161865540780127
step: 70 , loss: 0.0007120991358533502
0.0004621398984454572
step: 80 , loss: 0.00017008607392199337
0.0004233366344124079
step: 90 , loss: 0.0025780778378248215
0.0012164065847173333
step: 100 , loss: 0.0004841730697080493
0.000613790878560394
step: 110 , loss: 0.0011576837860047817
0.0009355862275697291
step: 120 , loss: 0.003597320755943656
0.004018932580947876
step: 130 , loss: 0.0008707514498382807
0.0017521439585834742
step: 140 , loss: 0.00031391915399581194
0.000270695862127468
step: 150 , loss: 0.00045516446698457
0.0004458364564925432
step: 160 , loss: 0.0004288962809368968
0.0004746549529954791
step: 170 , loss: 0.0007232060888782144
0.0017180631402879953
step: 180 , loss: 0.00037392060039564967
0.0008742368663661182
step: 190 , loss: 0.0012549583334475756
0.0014098775573074818
step: 200 , loss: 0.0001912275911308825
0.0005611399537883699
step: 210 , loss: 0.002644055522978306
0.0025189530570060015
step: 220 , loss: 0.0005701882764697075
0.0004553631879389286
step: 230 , loss: 0.0006921286694705486
0.00272549269720912
step: 240 , loss: 0.00139850121922791
0.001453680102713406
step: 250 , loss: 0.0006062138127163053
0.00021472106163855642
step: 260 , loss: 0.0007471709977835417
0.0004847039235755801
step: 270 , loss: 0.0014662012690678239
0.0009283641702495515
step: 280 , loss: 0.0006184132071211934
0.00032084615668281913
step: 290 , loss: 0.0004027538816444576
0.00048652413534000516
step: 300 , loss: 0.0004511059378273785
0.00029869386344216764
step: 310 , loss: 0.000925692729651928
0.0004416295560076833
step: 320 , loss: 0.00030371459433808923
0.00014318767352961004
step: 330 , loss: 0.00019276211969554424
0.00021282648958731443
step: 340 , loss: 0.00014376339095178992
0.00021844620641786605
step: 350 , loss: 0.0006303814006969333
0.0010323722381144762
step: 360 , loss: 0.0005361884832382202
0.0002419717056909576
step: 370 , loss: 0.00023287913063541055
0.0007590741151943803
step: 380 , loss: 0.0001852215500548482
0.0004980962839908898
step: 390 , loss: 0.017983485013246536
0.015010525472462177
step: 400 , loss: 0.0005608840147033334
0.0001677209511399269
step: 410 , loss: 0.0004069059214089066
0.0012808081228286028
step: 420 , loss: 9.154035069514066e-05
0.00015705458645243198
step: 430 , loss: 0.0010631063487380743
0.002419230528175831
step: 440 , loss: 0.003240459831431508
0.00025618248037062585
step: 450 , loss: 0.0004661075072363019
0.0008008864242583513
step: 460 , loss: 0.00019649561727419496
0.0005370643339119852
step: 470 , loss: 0.00043133494909852743
0.00021036139514762908
step: 480 , loss: 0.00022649019956588745
0.00019047655223403126
step: 490 , loss: 6.550403486471623e-05
0.0002516244712751359
step: 500 , loss: 0.000392392830690369
0.00028186265262775123
lr: 0.01
activation function type: relu
depth: 2
width: 20
test_loss: 0.00029500597156584263
