0.002513776878247484
(tensor([6.5132], device='cuda:0'), tensor([0.2295], device='cuda:0'))
3500
Net(
  (inp_layer): Linear(in_features=1, out_features=20, bias=True)
  (hiddens): ModuleList(
    (0): Linear(in_features=20, out_features=20, bias=True)
  )
  (out_layer): Linear(in_features=20, out_features=1, bias=True)
)
step: 10 , loss: 0.01469742227345705
0.03332386910915375
step: 20 , loss: 0.009823497384786606
0.018774399533867836
step: 30 , loss: 0.004026609472930431
0.0069952914491295815
step: 40 , loss: 0.005880780518054962
0.008027119562029839
step: 50 , loss: 0.008477862924337387
0.006509034428745508
step: 60 , loss: 0.007450941018760204
0.05171510949730873
step: 70 , loss: 0.002712465589866042
0.006146836560219526
step: 80 , loss: 0.0031247383449226618
0.0031459112651646137
step: 90 , loss: 0.000873684068210423
0.00202350877225399
step: 100 , loss: 0.0027171752881258726
0.001799538265913725
step: 110 , loss: 0.0007825109059922397
0.0015521927271038294
step: 120 , loss: 0.0033493724185973406
0.002076235134154558
step: 130 , loss: 0.0015619079349562526
0.0012974670389667153
step: 140 , loss: 0.0011622231686487794
0.0014889214653521776
step: 150 , loss: 0.001104737282730639
0.001309974119067192
step: 160 , loss: 0.0014306465163826942
0.0021048965863883495
step: 170 , loss: 0.0032660223077982664
0.0019325497560203075
step: 180 , loss: 0.0008106797467917204
0.0023298608139157295
step: 190 , loss: 0.004742717370390892
0.0017415599431842566
step: 200 , loss: 0.0012910686200484633
0.008375686593353748
step: 210 , loss: 0.0008384030079469085
0.000691503519192338
step: 220 , loss: 0.000543021596968174
0.003637308022007346
step: 230 , loss: 0.0012363031273707747
0.0015742428367957473
step: 240 , loss: 0.0016233406495302916
0.001041026902385056
step: 250 , loss: 0.003497626166790724
0.0010102431988343596
step: 260 , loss: 0.0018412681529298425
0.0039686961099505424
step: 270 , loss: 0.0016802983591333032
0.0026798343751579523
step: 280 , loss: 0.006831268314272165
0.0013610341120511293
step: 290 , loss: 0.0014821697259321809
0.001299375668168068
step: 300 , loss: 0.0021963194012641907
0.00114715239033103
step: 310 , loss: 0.0018147181253880262
0.0010790585074573755
step: 320 , loss: 0.0012630729470402002
0.0018714774632826447
step: 330 , loss: 0.0005532975774258375
0.0009574307478033006
step: 340 , loss: 0.0007969933794811368
0.0018151249969378114
step: 350 , loss: 0.0015865007881075144
0.0006969976238906384
step: 360 , loss: 0.001023238175548613
0.0010084796231240034
step: 370 , loss: 0.0011818986386060715
0.0006452069501392543
step: 380 , loss: 0.0005232270923443139
0.0012383529683575034
step: 390 , loss: 0.001337991445325315
0.0012962105683982372
step: 400 , loss: 0.0007939237402752042
0.002211114624515176
step: 410 , loss: 0.00037636846536770463
0.0011639678850769997
step: 420 , loss: 0.0060273087583482265
0.004773174878209829
step: 430 , loss: 0.0014286640798673034
0.0014927455922588706
step: 440 , loss: 0.0010376214049756527
0.0022740745916962624
step: 450 , loss: 0.0021812256891280413
0.002739404095336795
step: 460 , loss: 0.0005085985758341849
0.0006549244862981141
step: 470 , loss: 0.0007975482731126249
0.0011642150348052382
step: 480 , loss: 0.015632392838597298
0.015931496396660805
step: 490 , loss: 0.0003471503732725978
0.001005689729936421
step: 500 , loss: 0.000839571061078459
0.0010711626382544637
lr: 0.01
activation function type: relu
depth: 2
width: 20
test_loss: 0.0010812616674229503
