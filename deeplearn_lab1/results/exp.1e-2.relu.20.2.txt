step: 10 , loss: 0.03585100919008255
0.05551041662693024
step: 20 , loss: 0.008327938616275787
0.00557649414986372
step: 30 , loss: 0.0017598671838641167
0.0030412108171731234
step: 40 , loss: 0.0013227651361376047
0.001787330023944378
step: 50 , loss: 0.00112761533819139
0.0012544632190838456
step: 60 , loss: 0.004307661205530167
0.0013954215683043003
step: 70 , loss: 0.0017606441397219896
0.003265142673626542
step: 80 , loss: 0.0010212045162916183
0.0007456147577613592
step: 90 , loss: 0.0006266793352551758
0.0008950514020398259
step: 100 , loss: 0.0005295885493978858
0.0006530866958200932
step: 110 , loss: 0.003039743984118104
0.0008724731742404401
step: 120 , loss: 0.0005828633438795805
0.0007185667054727674
step: 130 , loss: 0.0009101163013838232
0.0005823919200338423
step: 140 , loss: 0.00046453153481706977
0.0005223629414103925
step: 150 , loss: 0.0009002638980746269
0.0006839726702310145
step: 160 , loss: 0.0005217730649746954
0.001793585834093392
step: 170 , loss: 0.0006673440802842379
0.0011210305383428931
step: 180 , loss: 0.0012649514246731997
0.0005935688968747854
step: 190 , loss: 0.00045424519339576364
0.0012343819253146648
step: 200 , loss: 0.0012399640399962664
0.0005698847235180438
step: 210 , loss: 0.0002741083153523505
0.001009661704301834
step: 220 , loss: 0.0008460963144898415
0.0007755983388051391
step: 230 , loss: 0.000743354088626802
0.0006095197168178856
step: 240 , loss: 0.00032800185726955533
0.0007080837967805564
step: 250 , loss: 0.0004303815949242562
0.00046827085316181183
step: 260 , loss: 0.0031661391258239746
0.0005022211116738617
step: 270 , loss: 0.0011967472964897752
0.0019165818812325597
step: 280 , loss: 0.0006191113498061895
0.0004980884259566665
step: 290 , loss: 0.0005511661292985082
0.0019457584712654352
step: 300 , loss: 0.0008317644242197275
0.0006036592531017959
step: 310 , loss: 0.000723209057468921
0.0005145964678376913
step: 320 , loss: 0.000958258518949151
0.001855658134445548
step: 330 , loss: 0.0004445102531462908
0.0009223652305081487
step: 340 , loss: 0.00037811032962054014
0.0006936559220775962
step: 350 , loss: 0.0006210301071405411
0.0008076534722931683
step: 360 , loss: 0.0018245497485622764
0.0007592025212943554
step: 370 , loss: 0.0006304840208031237
0.0004612696939148009
step: 380 , loss: 0.001246580621227622
0.0017329853726550937
step: 390 , loss: 0.0032815327867865562
0.0043121338821947575
step: 400 , loss: 0.00156290119048208
0.008463766425848007
step: 410 , loss: 0.00227352068759501
0.001238436670973897
step: 420 , loss: 0.0004459827032405883
0.0005270320107229054
step: 430 , loss: 0.0007726770709268749
0.00089008774375543
step: 440 , loss: 0.0031517839524894953
0.000965205195825547
step: 450 , loss: 0.0007666576420888305
0.0009751422912813723
step: 460 , loss: 0.002813451923429966
0.0016411887481808662
step: 470 , loss: 0.0004898727056570351
0.0015336242504417896
step: 480 , loss: 0.001225627725943923
0.0008842243696562946
step: 490 , loss: 0.0006769377505406737
0.0010131940944120288
step: 500 , loss: 0.0006577698513865471
0.0007985371630638838
lr: 0.01
activation function type: relu
depth: 2
width: 20
test_loss: 0.0008320594788528979
