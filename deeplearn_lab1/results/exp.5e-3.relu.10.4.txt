Net(
  (inp_layer): Linear(in_features=1, out_features=10, bias=True)
  (hiddens): ModuleList(
    (0): Linear(in_features=10, out_features=10, bias=True)
    (1): Linear(in_features=10, out_features=10, bias=True)
    (2): Linear(in_features=10, out_features=10, bias=True)
  )
  (out_layer): Linear(in_features=10, out_features=1, bias=True)
)
step: 10 , loss: 0.018164975568652153
0.026066357269883156
step: 20 , loss: 0.012740555219352245
0.019105521962046623
step: 30 , loss: 0.00022636186622548848
0.0020775587763637304
step: 40 , loss: 0.00032705769990570843
0.00029865559190511703
step: 50 , loss: 0.00018391951743979007
0.00031022491748444736
step: 60 , loss: 0.00045443273847922683
0.000254713260801509
step: 70 , loss: 0.00033623658237047493
0.0013145522680133581
step: 80 , loss: 0.0006907903589308262
0.0003268657310400158
step: 90 , loss: 0.00041512399911880493
0.0008569128694944084
step: 100 , loss: 0.0007213149219751358
0.0005909668398089707
step: 110 , loss: 0.0009302269900217652
0.0013469236437231302
step: 120 , loss: 0.00023925289860926569
0.0003321617841720581
step: 130 , loss: 0.00033181364415213466
0.00013899971963837743
step: 140 , loss: 0.0010620086686685681
0.0029824215453118086
step: 150 , loss: 0.0008029000600799918
0.0009806175949051976
step: 160 , loss: 0.00019062466162722558
0.00012824515579268336
step: 170 , loss: 0.00035551947075873613
0.0003083273477386683
step: 180 , loss: 0.00015452649677172303
0.00036148569779470563
step: 190 , loss: 0.00039800434024073184
0.00018020434072241187
step: 200 , loss: 0.0002003111585509032
0.0002670992980711162
step: 210 , loss: 0.0008640991291031241
0.0015574591234326363
step: 220 , loss: 0.0002809949219226837
0.0005705667426809669
step: 230 , loss: 0.0005059955292381346
0.00149045349098742
step: 240 , loss: 0.0001036036410368979
9.750879689818248e-05
step: 250 , loss: 0.00023563804279547185
0.0002148523781215772
step: 260 , loss: 0.00031071167904883623
0.0008232615073211491
step: 270 , loss: 0.0005278010503388941
0.0004772869579028338
step: 280 , loss: 0.0003195122699253261
0.0007869932451285422
step: 290 , loss: 0.0003808782494161278
8.71242446010001e-05
step: 300 , loss: 0.00021811551414430141
0.00018295735935680568
step: 310 , loss: 0.0002574686659500003
0.0003869167121592909
step: 320 , loss: 0.0006769302417524159
0.0001524137333035469
step: 330 , loss: 0.0010393529664725065
0.0014049028977751732
step: 340 , loss: 0.00010936742910416797
8.883989357855171e-05
step: 350 , loss: 0.0001730511139612645
0.00014461261162068695
step: 360 , loss: 0.0003125708899460733
0.0003676321648526937
step: 370 , loss: 0.00034719036193564534
0.00026418702327646315
step: 380 , loss: 0.00020959071116521955
0.00021109382214490324
step: 390 , loss: 0.0002165873593185097
0.00012291647726669908
step: 400 , loss: 8.132473158184439e-05
9.915690316120163e-05
step: 410 , loss: 9.131320257438347e-05
0.00010453058348502964
step: 420 , loss: 0.00030565180350095034
0.0008144043968059123
step: 430 , loss: 0.00012167658860562369
0.00010344888869440183
step: 440 , loss: 7.375417044386268e-05
0.0002163763128919527
step: 450 , loss: 0.00013262622815091163
0.0001558092626510188
step: 460 , loss: 0.00017301421030424535
0.00017852075689006597
step: 470 , loss: 0.0010183443082496524
0.0020044308621436357
step: 480 , loss: 9.44538478506729e-05
0.00012037589476676658
step: 490 , loss: 0.0002826078562065959
0.0002664935018401593
step: 500 , loss: 0.0002426047285553068
0.00022455421276390553
lr: 0.005
activation function type: relu
depth: 4
width: 10
test_loss: 0.00023489640443585813
