0.002513776878247484
(tensor([6.5132], device='cuda:0'), tensor([0.2295], device='cuda:0'))
3500
Net(
  (inp_layer): Linear(in_features=1, out_features=10, bias=True)
  (hiddens): ModuleList(
    (0): Linear(in_features=10, out_features=10, bias=True)
    (1): Linear(in_features=10, out_features=10, bias=True)
    (2): Linear(in_features=10, out_features=10, bias=True)
  )
  (out_layer): Linear(in_features=10, out_features=1, bias=True)
)
step: 10 , loss: 0.04109327867627144
0.03155028074979782
step: 20 , loss: 0.001258640200830996
0.001701059634797275
step: 30 , loss: 0.0003744513669516891
0.00045563597814179957
step: 40 , loss: 0.000553752004634589
0.0012675957987084985
step: 50 , loss: 0.000900557788554579
0.0005118161207064986
step: 60 , loss: 0.0012134223943576217
0.00033822504337877035
step: 70 , loss: 0.00013915933959651738
0.00031202990794554353
step: 80 , loss: 0.002771148458123207
0.0013542692176997662
step: 90 , loss: 0.0003061512252315879
0.0005803141975775361
step: 100 , loss: 0.00019561084627639502
0.00022824130428489298
step: 110 , loss: 0.0007698231493122876
0.0004201860283501446
step: 120 , loss: 0.0007688385667279363
0.0008647742215543985
step: 130 , loss: 0.0003949422389268875
0.0002177924761781469
step: 140 , loss: 0.004858109168708324
0.0039323437958955765
step: 150 , loss: 0.00011980254203081131
0.00016232255438808352
step: 160 , loss: 0.0008286961237899959
0.00045740712084807456
step: 170 , loss: 0.00035545180435292423
0.0009358897223137319
step: 180 , loss: 0.00012892470113001764
0.00019013434939552099
step: 190 , loss: 0.00041703114402480423
0.004449930042028427
step: 200 , loss: 0.00019873434212058783
0.00045275676529854536
step: 210 , loss: 0.0004918021149933338
0.00034046292421408
step: 220 , loss: 0.000353688228642568
0.00020315498113632202
step: 230 , loss: 9.712183236842975e-05
6.882136221975088e-05
step: 240 , loss: 0.00011752499267458916
9.477432467974722e-05
step: 250 , loss: 0.00012871318904217333
0.00022497394820675254
step: 260 , loss: 0.0001910430728457868
0.0001639900729060173
step: 270 , loss: 0.00012339513341430575
9.95966765913181e-05
step: 280 , loss: 0.0008954752120189369
0.00047470530262216926
step: 290 , loss: 0.00044053452438674867
0.0003035698609892279
step: 300 , loss: 6.285615381784737e-05
6.501230382127687e-05
step: 310 , loss: 0.0028486414812505245
0.005465474911034107
step: 320 , loss: 5.563147715292871e-05
7.270028436323628e-05
step: 330 , loss: 0.0002411419409327209
0.00013204620336182415
step: 340 , loss: 7.810087845427915e-05
0.0002376089832978323
step: 350 , loss: 0.0010302722221240401
0.00023426409461535513
step: 360 , loss: 0.0002132953522959724
0.0006023009773343801
step: 370 , loss: 0.00013263319851830602
0.0003382133145350963
step: 380 , loss: 0.00014642317546531558
0.00014015768829267472
step: 390 , loss: 7.12489418219775e-05
0.00011728340177796781
step: 400 , loss: 0.0007929302519187331
0.0002527402248233557
step: 410 , loss: 0.00101506058126688
0.00024984762421809137
step: 420 , loss: 8.03846851340495e-05
0.00013172862236388028
step: 430 , loss: 5.9265112213324755e-05
0.00014125397137831897
step: 440 , loss: 7.224996079457924e-05
0.00010968798596877605
step: 450 , loss: 0.00023900935775600374
0.0002082961000269279
step: 460 , loss: 0.00021214042499195784
0.0004908189876005054
step: 470 , loss: 0.00028900205506943166
9.284728730563074e-05
step: 480 , loss: 0.0004948319983668625
0.0003869023348670453
step: 490 , loss: 7.151264435378835e-05
6.973362906137481e-05
step: 500 , loss: 0.0004937940975651145
0.0001867521641543135
lr: 0.005
activation function type: relu
depth: 4
width: 10
test_loss: 0.00022453063866123557
