step: 10 , loss: 0.33736616373062134
0.3579099178314209
step: 20 , loss: 0.2201095074415207
0.2837754786014557
step: 30 , loss: 0.24610839784145355
0.2252284288406372
step: 40 , loss: 0.19455349445343018
0.16729465126991272
step: 50 , loss: 0.10739873349666595
0.10705718398094177
step: 60 , loss: 0.08000920712947845
0.06491570174694061
step: 70 , loss: 0.04164047911763191
0.03473569452762604
step: 80 , loss: 0.015660958364605904
0.018806906417012215
step: 90 , loss: 0.01439282763749361
0.012107237242162228
step: 100 , loss: 0.005045390222221613
0.009625624865293503
step: 110 , loss: 0.006052480079233646
0.008844704367220402
step: 120 , loss: 0.005656905006617308
0.008578922599554062
step: 130 , loss: 0.009255656972527504
0.00811537355184555
step: 140 , loss: 0.006172336172312498
0.008020670153200626
step: 150 , loss: 0.006713016889989376
0.007454308215528727
step: 160 , loss: 0.009305883198976517
0.007934367284178734
step: 170 , loss: 0.011681179516017437
0.006941604427993298
step: 180 , loss: 0.007171336095780134
0.0067120823077857494
step: 190 , loss: 0.00834617204964161
0.006485078949481249
step: 200 , loss: 0.0038474504835903645
0.0063550169579684734
step: 210 , loss: 0.007309882435947657
0.005688238423317671
step: 220 , loss: 0.0028768908232450485
0.005302282981574535
step: 230 , loss: 0.004853215999901295
0.005082426592707634
step: 240 , loss: 0.0026057776995003223
0.004733582027256489
step: 250 , loss: 0.004704607650637627
0.0049550822004675865
step: 260 , loss: 0.002707097679376602
0.00426656287163496
step: 270 , loss: 0.002328192349523306
0.004175287671387196
step: 280 , loss: 0.002672562375664711
0.0037037597503513098
step: 290 , loss: 0.0046556368470191956
0.0034918109886348248
step: 300 , loss: 0.006019999273121357
0.003987266682088375
step: 310 , loss: 0.0010462736245244741
0.003336435416713357
step: 320 , loss: 0.0019504609517753124
0.0032239973079413176
step: 330 , loss: 0.0023754751309752464
0.0033857885282486677
step: 340 , loss: 0.004952328745275736
0.003171959426254034
step: 350 , loss: 0.002489460399374366
0.0032899444922804832
step: 360 , loss: 0.0018008138285949826
0.0030017143581062555
step: 370 , loss: 0.002268770942464471
0.0034715840592980385
step: 380 , loss: 0.005116561893373728
0.0029411790892481804
step: 390 , loss: 0.0022090384736657143
0.0035729550290852785
step: 400 , loss: 0.003356985282152891
0.0034227061551064253
step: 410 , loss: 0.0015061326557770371
0.0028745592571794987
step: 420 , loss: 0.0026772436685860157
0.0028720858972519636
step: 430 , loss: 0.0013300320133566856
0.0029544702265411615
step: 440 , loss: 0.002049940638244152
0.0029294223058968782
step: 450 , loss: 0.004343344829976559
0.002962755970656872
step: 460 , loss: 0.0017570059280842543
0.0031047819647938013
step: 470 , loss: 0.003733381163328886
0.003175081918016076
step: 480 , loss: 0.002200166927650571
0.002738903509452939
step: 490 , loss: 0.0022429008968174458
0.0029813277069479227
step: 500 , loss: 0.005583587568253279
0.0028426332864910364
lr: 0.005
activation function type: relu
depth: 4
width: 10
test_loss: 0.0029730908572673798
