step: 10 , loss: 0.3543163537979126
0.31572484970092773
step: 20 , loss: 0.3176300525665283
0.2151525467634201
step: 30 , loss: 0.11306022852659225
0.12046222388744354
step: 40 , loss: 0.055402010679244995
0.058944087475538254
step: 50 , loss: 0.03958652913570404
0.0362992025911808
step: 60 , loss: 0.03655252605676651
0.029985371977090836
step: 70 , loss: 0.01854104921221733
0.028269488364458084
step: 80 , loss: 0.02244085818529129
0.02619178406894207
step: 90 , loss: 0.017329176887869835
0.023061327636241913
step: 100 , loss: 0.01768818125128746
0.021689701825380325
step: 110 , loss: 0.009380217641592026
0.020248498767614365
step: 120 , loss: 0.010722782462835312
0.01849515736103058
step: 130 , loss: 0.012886347249150276
0.017257973551750183
step: 140 , loss: 0.03904290497303009
0.015694331377744675
step: 150 , loss: 0.009568693116307259
0.014714735560119152
step: 160 , loss: 0.015796268358826637
0.014229325577616692
step: 170 , loss: 0.004706795793026686
0.012652107514441013
step: 180 , loss: 0.008511722087860107
0.012146798893809319
step: 190 , loss: 0.010261818766593933
0.01117106806486845
step: 200 , loss: 0.0023623427841812372
0.011026552878320217
step: 210 , loss: 0.00338056986220181
0.00895447563380003
step: 220 , loss: 0.008150331676006317
0.008748277090489864
step: 230 , loss: 0.0034808083437383175
0.008127719163894653
step: 240 , loss: 0.006079038139432669
0.00729081267490983
step: 250 , loss: 0.0061319866217672825
0.007108363322913647
step: 260 , loss: 0.001860460382886231
0.006091095041483641
step: 270 , loss: 0.013371138833463192
0.005597542505711317
step: 280 , loss: 0.002125435508787632
0.005061720963567495
step: 290 , loss: 0.007298978045582771
0.00477416068315506
step: 300 , loss: 0.0021523977629840374
0.004759588278830051
step: 310 , loss: 0.0021056607365608215
0.006090432871133089
step: 320 , loss: 0.00577090959995985
0.004149006679654121
step: 330 , loss: 0.0054048821330070496
0.0037479945458471775
step: 340 , loss: 0.007227995898574591
0.0036808273289352655
step: 350 , loss: 0.0032117697410285473
0.003390343626961112
step: 360 , loss: 0.002186995232477784
0.003378354711458087
step: 370 , loss: 0.0024102586321532726
0.003646472468972206
step: 380 , loss: 0.0029756417497992516
0.003476428799331188
step: 390 , loss: 0.0026540441904217005
0.0028766077011823654
step: 400 , loss: 0.002995338523760438
0.002710889559239149
step: 410 , loss: 0.00275985524058342
0.002599806757643819
step: 420 , loss: 0.003134939819574356
0.003003922523930669
step: 430 , loss: 0.0033262846991419792
0.0029884278774261475
step: 440 , loss: 0.00454589631408453
0.002611906034871936
step: 450 , loss: 0.0011320298071950674
0.0024518556892871857
step: 460 , loss: 0.001996175851672888
0.0023896144703030586
step: 470 , loss: 0.001649818615987897
0.0024257097393274307
step: 480 , loss: 0.002968813292682171
0.002348589012399316
step: 490 , loss: 0.0026598088443279266
0.002420567674562335
step: 500 , loss: 0.006028440780937672
0.0032771367114037275
lr: 0.005
activation function type: relu
depth: 3
width: 13
test_loss: 0.003388349199667573
