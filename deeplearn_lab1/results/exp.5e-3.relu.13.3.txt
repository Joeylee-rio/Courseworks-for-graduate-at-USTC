0.002513776878247484
(tensor([6.5132], device='cuda:0'), tensor([0.2295], device='cuda:0'))
3500
Net(
  (inp_layer): Linear(in_features=1, out_features=13, bias=True)
  (hiddens): ModuleList(
    (0): Linear(in_features=13, out_features=13, bias=True)
    (1): Linear(in_features=13, out_features=13, bias=True)
  )
  (out_layer): Linear(in_features=13, out_features=1, bias=True)
)
step: 10 , loss: 0.021127918735146523
0.057552091777324677
step: 20 , loss: 0.027251645922660828
0.023368464782834053
step: 30 , loss: 0.016765231266617775
0.016630327329039574
step: 40 , loss: 0.019933396950364113
0.007241755723953247
step: 50 , loss: 0.0016295890090987086
0.002829338423907757
step: 60 , loss: 0.0024489164352416992
0.000980695360340178
step: 70 , loss: 0.004763890523463488
0.015588589012622833
step: 80 , loss: 0.0011724064825102687
0.0013258568942546844
step: 90 , loss: 0.0007387594669125974
0.0006480349111370742
step: 100 , loss: 0.0004930084105581045
0.00043308333260938525
step: 110 , loss: 0.002764565171673894
0.005286564584821463
step: 120 , loss: 0.0005922880955040455
0.0011114149820059538
step: 130 , loss: 0.0005179953295737505
0.00042855978244915605
step: 140 , loss: 0.0005052658962085843
0.0013659031828865409
step: 150 , loss: 0.0006879876018501818
0.0004968557041138411
step: 160 , loss: 0.001550617627799511
0.000579790270421654
step: 170 , loss: 0.0007910022395662963
0.0009174273582175374
step: 180 , loss: 0.002793744904920459
0.001156449900008738
step: 190 , loss: 0.00018929335055872798
0.0005040520336478949
step: 200 , loss: 0.00022831675596535206
0.00018513052782509476
step: 210 , loss: 0.00016248294559773058
0.00023663668252993375
step: 220 , loss: 0.0007383994525298476
0.0019552253652364016
step: 230 , loss: 0.0002456835354678333
0.0007159197120927274
step: 240 , loss: 0.00014670754899270833
0.00019889821123797446
step: 250 , loss: 0.0001752355310600251
0.00014291259867604822
step: 260 , loss: 0.0002828566066455096
0.00017968591419048607
step: 270 , loss: 0.0004203717107884586
0.00016907443932723254
step: 280 , loss: 0.00015935988631099463
0.000179131850018166
step: 290 , loss: 0.0005490401526913047
0.00037018011789768934
step: 300 , loss: 0.000351712922565639
0.000297608959954232
step: 310 , loss: 0.0002130085922544822
0.00042773873428814113
step: 320 , loss: 0.0005762842483818531
0.0011869394220411777
step: 330 , loss: 0.0008705243235453963
0.0006537082372233272
step: 340 , loss: 0.0010368074290454388
0.0003353776119183749
step: 350 , loss: 0.00023135606897994876
0.00023074752243701369
step: 360 , loss: 0.00023842311929911375
0.0008562133880332112
step: 370 , loss: 0.00041886381222866476
0.0006892738165333867
step: 380 , loss: 0.0001469462877139449
0.0002916617668233812
step: 390 , loss: 0.00045876350486651063
0.0002654154959600419
step: 400 , loss: 0.0009226189577020705
0.0007068081758916378
step: 410 , loss: 0.00015917274868115783
0.001257855910807848
step: 420 , loss: 0.00046847815974615514
0.0004976065247319639
step: 430 , loss: 0.0002551584620960057
0.000373487186152488
step: 440 , loss: 0.0003734873316716403
0.00024971802486106753
step: 450 , loss: 0.0007556633790954947
0.0002642716281116009
step: 460 , loss: 0.0005902493139728904
0.0009141799528151751
step: 470 , loss: 0.0003913344698958099
0.00025104256928898394
step: 480 , loss: 0.0003677529748529196
0.0002721885102801025
step: 490 , loss: 0.00021838283282704651
0.00025063438806682825
step: 500 , loss: 0.0006999740726314485
0.00017728527018334717
lr: 0.005
activation function type: relu
depth: 3
width: 13
test_loss: 0.00017655917326919734
