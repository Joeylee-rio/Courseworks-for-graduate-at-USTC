Net(
  (inp_layer): Linear(in_features=1, out_features=13, bias=True)
  (hiddens): ModuleList(
    (0): Linear(in_features=13, out_features=13, bias=True)
    (1): Linear(in_features=13, out_features=13, bias=True)
  )
  (out_layer): Linear(in_features=13, out_features=1, bias=True)
)
step: 10 , loss: 0.025318169966340065
0.029883258044719696
step: 20 , loss: 0.007986065000295639
0.01256430521607399
step: 30 , loss: 0.0010274085216224194
0.001997942803427577
step: 40 , loss: 0.0008868844015523791
0.0006511050742119551
step: 50 , loss: 0.0005074089276604354
0.004152292385697365
step: 60 , loss: 0.000685356673784554
0.0006119378958828747
step: 70 , loss: 0.0005575803807005286
0.0004904004163108766
step: 80 , loss: 0.003758832812309265
0.0016737296245992184
step: 90 , loss: 0.0001268632331630215
0.0010542114032432437
step: 100 , loss: 0.00012481893645599484
0.0005448098527267575
step: 110 , loss: 0.0009145931689999998
0.0008302637143060565
step: 120 , loss: 0.0052675893530249596
0.0013081487268209457
step: 130 , loss: 0.0009866724722087383
0.0005887338775210083
step: 140 , loss: 0.0006464804755523801
0.0008248256635852158
step: 150 , loss: 0.000306202273350209
0.0006411803769879043
step: 160 , loss: 0.0003148196847178042
0.0005454118363559246
step: 170 , loss: 0.0003630254650488496
0.00028029203531332314
step: 180 , loss: 0.0008036824292503297
0.0007108005811460316
step: 190 , loss: 0.00028563878731802106
0.0003780570114031434
step: 200 , loss: 0.0001833689457271248
0.0013640433317050338
step: 210 , loss: 0.0003887010389007628
0.0010553961619734764
step: 220 , loss: 0.0001992152538150549
0.0004366898792795837
step: 230 , loss: 0.002102742437273264
0.0027318813372403383
step: 240 , loss: 0.00035097560612484813
0.0002561981091275811
step: 250 , loss: 0.0007900569471530616
0.0037331811618059874
step: 260 , loss: 0.0003050091618206352
0.0002990670327562839
step: 270 , loss: 0.0007337526767514646
0.0022851992398500443
step: 280 , loss: 0.00029388145776465535
0.00046045187627896667
step: 290 , loss: 0.0005625518970191479
0.002586226910352707
step: 300 , loss: 0.0019655940122902393
0.0005691684782505035
step: 310 , loss: 0.00017212974489666522
0.00023404053354170173
step: 320 , loss: 0.00020076739019714296
0.0007810679962858558
step: 330 , loss: 0.00017729090177454054
0.00040298851672559977
step: 340 , loss: 0.0003724812704604119
0.0002232585393358022
step: 350 , loss: 0.00032622067374177277
0.0002821178059093654
step: 360 , loss: 0.0005730559350922704
0.003576419083401561
step: 370 , loss: 0.0001363224582746625
0.00017189506615977734
step: 380 , loss: 0.0001738883147481829
0.0004398781748022884
step: 390 , loss: 0.00011817144695669413
0.0001238855766132474
step: 400 , loss: 0.00013340526493266225
0.00024075491819530725
step: 410 , loss: 0.00020020021474920213
0.00019022727792616934
step: 420 , loss: 0.000181003546458669
0.0001728084753267467
step: 430 , loss: 0.0001882969227153808
0.0004216812376398593
step: 440 , loss: 0.00010104024840984493
0.00011745104711735621
step: 450 , loss: 0.00013808999210596085
0.0003157162282150239
step: 460 , loss: 0.00014297771849669516
0.0001726985938148573
step: 470 , loss: 0.0001685491733951494
0.0010675301309674978
step: 480 , loss: 0.0008961075218394399
0.0008877136278897524
step: 490 , loss: 0.0011168622877448797
0.0004151675966568291
step: 500 , loss: 0.0004130768938921392
0.00020310989930294454
lr: 0.005
activation function type: relu
depth: 3
width: 13
test_loss: 0.0002066468878183514
